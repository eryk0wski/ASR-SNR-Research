{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "import os\n",
    "from data_engineering import *\n",
    "from audio_mixer import mixer\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading whole bigos v2 polish ASR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for amu-cai/pl-asr-bigos-v2 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/amu-cai/pl-asr-bigos-v2\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56697fda587a4fe1a186176e0cc9dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"amu-cai/pl-asr-bigos-v2\",'all', 'all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataframe from the training set with 5000 randomly chosen examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input must be a DataFrame or a dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_model_testing \u001b[38;5;241m=\u001b[39m creating_random_split_df(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_model_testing\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mcreating_random_split_df\u001b[1;34m(data, batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreating_random_split_df\u001b[39m(data,batch):    \n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Check if the input is a DataFrame or a dictionary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m----> 6\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a DataFrame or a dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     total_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# if size of batch is bigger than database\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Input must be a DataFrame or a dictionary."
     ]
    }
   ],
   "source": [
    "df_model_testing = creating_random_split_df(data['train'], 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving audio files to the folder in project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder_path = './data/testing_batch/clear/'\n",
    "copy_files(df_model_testing, 'audiopath_local', target_folder_path)\n",
    "df_model_testing['audiopath_project'] = target_folder_path + df_model_testing['audiopath_bigos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dataframe to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_model_testing[['audioname','dataset','ref_orig','sampling_rate','audiopath_local','audiopath_project']]\n",
    "df_testing.to_parquet('testing_batch_df.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_sounds = pd.read_csv('./data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "df_urban_sounds = df_urban_sounds[~df_urban_sounds['classID'].isin([2, 5, 9])]\n",
    "df_urban_shuffled = creating_random_split_df(df_urban_sounds,3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the file path\n",
    "def create_file_path(row, folder_path):\n",
    "    folder_number = row['fold']\n",
    "    file_name = row['slice_file_name']\n",
    "    file_path = os.path.join(folder_path, f'fold{folder_number}', file_name)\n",
    "    return file_path\n",
    "\n",
    "base_path = '.\\\\data\\\\UrbanSound8K\\\\audio\\\\'\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df_urban_shuffled['audio_path'] = df_urban_shuffled.apply(create_file_path, axis=1, folder_path=base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visc_folder_path = '.\\\\data\\\\VISC Dataset SON\\\\'\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "class_ids = []\n",
    "\n",
    "\n",
    "# Traverse the directory\n",
    "for filename in os.listdir(visc_folder_path):\n",
    "    # Join the folder path with the filename to get the full file path\n",
    "    file_path = os.path.join(visc_folder_path, filename)\n",
    "    \n",
    "    # Extract the class ID from the file name\n",
    "    class_id = int(filename.split()[0])\n",
    "    \n",
    "    # Append the values to the lists\n",
    "    file_paths.append(file_path)\n",
    "    class_ids.append(class_id)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'file_path': file_paths, 'class_id': class_ids})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visc_noises_dataframe = creating_random_split_df(df,1500)\n",
    "\n",
    "visc_noises_dict = {1 : 'bus_interior',\n",
    "                    2 : 'minibus_interior',\n",
    "                    3 : 'pickup_interior',\n",
    "                    4 : 'sports_car_interior',\n",
    "                    5 : 'jeep_interior',\n",
    "                    6 : 'truck_interior',\n",
    "                    7 : 'crossover_interior',\n",
    "                    8 : 'other_car_interior'}\n",
    "visc_noises_dataframe['class'] = visc_noises_dataframe['class_id'].map(visc_noises_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_combined_df = pd.merge(visc_noises_dataframe[['file_path', 'class']],df_urban_shuffled[['audio_path', 'class']], left_index=True, right_index=True, how='outer')\n",
    "\n",
    "noise_combined_df.rename(columns={'file_path': 'noise_path'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading work dataframe from parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_local</th>\n",
       "      <th>audiopath_project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01818</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Jest także trzecia sprawa, która w czasie tej ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0457-00001</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dżuma  wziernik  przemianę  księdzu  krzywdzen...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0083-00007</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w piątek po południu była przesłuchiwana przez...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pwr-maleset-unk-train-0001-03097</td>\n",
       "      <td>pwr-maleset-unk</td>\n",
       "      <td>jeśli chcesz zostanę w domu</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pwr-maleset-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2862-00017</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Tekst nie opiera się na żadnych podstawach nau...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-2023-00011</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>Nareszcie zniecierpliwiony kazał zamurować okn...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mailabs-corpus_libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0289-00016</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dostała  za  ten  reportaż  nagrodę  pulicera ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2846-00448</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Dotyczy ona zasadniczo dwóch kwestii</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0035-00018</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>każdy starał się odlecieć najbliższym samolote...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0060-00012</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w tym roku zacznie się zaś budowa dodatkowych ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname                     dataset  \\\n",
       "0     mozilla-common_voice_15-23-train-2856-01818  mozilla-common_voice_15-23   \n",
       "1         pjatk-clarin_studio-15-train-0457-00001      pjatk-clarin_studio-15   \n",
       "2         pjatk-clarin_mobile-15-train-0083-00007      pjatk-clarin_mobile-15   \n",
       "3                pwr-maleset-unk-train-0001-03097             pwr-maleset-unk   \n",
       "4     mozilla-common_voice_15-23-train-2862-00017  mozilla-common_voice_15-23   \n",
       "...                                           ...                         ...   \n",
       "4995  mailabs-corpus_librivox-19-train-2023-00011  mailabs-corpus_librivox-19   \n",
       "4996      pjatk-clarin_studio-15-train-0289-00016      pjatk-clarin_studio-15   \n",
       "4997  mozilla-common_voice_15-23-train-2846-00448  mozilla-common_voice_15-23   \n",
       "4998      pjatk-clarin_mobile-15-train-0035-00018      pjatk-clarin_mobile-15   \n",
       "4999      pjatk-clarin_mobile-15-train-0060-00012      pjatk-clarin_mobile-15   \n",
       "\n",
       "                                               ref_orig  sampling_rate  \\\n",
       "0     Jest także trzecia sprawa, która w czasie tej ...          16000   \n",
       "1     dżuma  wziernik  przemianę  księdzu  krzywdzen...          16000   \n",
       "2     w piątek po południu była przesłuchiwana przez...          16000   \n",
       "3                           jeśli chcesz zostanę w domu          16000   \n",
       "4     Tekst nie opiera się na żadnych podstawach nau...          16000   \n",
       "...                                                 ...            ...   \n",
       "4995  Nareszcie zniecierpliwiony kazał zamurować okn...          16000   \n",
       "4996  dostała  za  ten  reportaż  nagrodę  pulicera ...          16000   \n",
       "4997               Dotyczy ona zasadniczo dwóch kwestii          16000   \n",
       "4998  każdy starał się odlecieć najbliższym samolote...          16000   \n",
       "4999  w tym roku zacznie się zaś budowa dodatkowych ...          16000   \n",
       "\n",
       "                                        audiopath_local  \\\n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "...                                                 ...   \n",
       "4995  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4996  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4997  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4998  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4999  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "\n",
       "                                      audiopath_project  \n",
       "0     ./data/testing_batch/clear/mozilla-common_voic...  \n",
       "1     ./data/testing_batch/clear/pjatk-clarin_studio...  \n",
       "2     ./data/testing_batch/clear/pjatk-clarin_mobile...  \n",
       "3     ./data/testing_batch/clear/pwr-maleset-unk-tra...  \n",
       "4     ./data/testing_batch/clear/mozilla-common_voic...  \n",
       "...                                                 ...  \n",
       "4995  ./data/testing_batch/clear/mailabs-corpus_libr...  \n",
       "4996  ./data/testing_batch/clear/pjatk-clarin_studio...  \n",
       "4997  ./data/testing_batch/clear/mozilla-common_voic...  \n",
       "4998  ./data/testing_batch/clear/pjatk-clarin_mobile...  \n",
       "4999  ./data/testing_batch/clear/pjatk-clarin_mobile...  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_models = pd.read_parquet('testing_batch_df.parquet.gzip') \n",
    "df_testing_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling noises from Urban Sounds and VISC Dataset to create one noises dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "visc_noises_df = visc_noises_dataframe[['file_path','class']]\n",
    "urban_noises_df = df_urban_shuffled[['audio_path','class']]\n",
    "urban_noises_df['file_path'] = urban_noises_df['audio_path']\n",
    "urban_noises_df_2 = urban_noises_df[['file_path','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = pd.concat([urban_noises_df_2,visc_noises_df],ignore_index=True)\n",
    "df_testing_models[['noise_path','noise_class']] = noise_df[['file_path','class']]\n",
    "df_testing_models.to_parquet('full_dataframe_with_noises.parquet.gzip', compression = 'gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading full dataframe from parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('full_dataframe_with_noises.parquet.gzip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating folders with mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_values = [100,50, 25, 10, 5, 1, 0.5, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through each SNR value\n",
    "for snr in snr_values:\n",
    "    # Create a folder for the current SNR value\n",
    "    folder_path = f'./data/mixed_recordings/SNR_{snr}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Loop through the dataframe and mix files for the current SNR value\n",
    "    for index, row in full_df.iterrows():\n",
    "        signal_path = row['audiopath_local']\n",
    "        noise_path = row['noise_path']\n",
    "        audio_name = row['audioname'] + '.wav'\n",
    "        save_path = os.path.join(folder_path, audio_name)  # Change the naming convention if needed\n",
    "\n",
    "        # Call your mixer function here\n",
    "        mixer(signal_path, noise_path, snr, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model bark whisper v3 Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# Specify the CUDA device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "torch_dtype = torch.float32  # You can adjust the dtype if needed\n",
    "\n",
    "# Load model and move it to CUDA\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create the pipeline with CUDA support\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc250fb12ee248ffa655d34503a6c1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "#whisper_results = []\n",
    "#for i in range(len(df_whisper)):\n",
    "#    sample = df_whisper['audiopath_local'][i]\n",
    "#    result = pipe(sample)\n",
    "#    whisper_results.append(result['text'])\n",
    "\n",
    "#df_whisper['whisper_pred'] = whisper_results\n",
    "results = []\n",
    "\n",
    "for i in trange(len(snr_dataframe)):\n",
    "    sample = snr_dataframe['SNR_10'][i]\n",
    "    result = pipe(sample, generate_kwargs={\"language\": \"polish\"})\n",
    "    results.append(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['whisper_SNR_100'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.1217381831866\n"
     ]
    }
   ],
   "source": [
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=full_df['whisper_SNR_100'], references=full_df['ref_orig'])\n",
    "print(wer_score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR_0.1</th>\n",
       "      <th>SNR_0.5</th>\n",
       "      <th>SNR_1</th>\n",
       "      <th>SNR_10</th>\n",
       "      <th>SNR_100</th>\n",
       "      <th>SNR_25</th>\n",
       "      <th>SNR_5</th>\n",
       "      <th>SNR_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SNR_0.1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                SNR_0.5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                  SNR_1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_10  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                SNR_100  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                 SNR_25  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                  SNR_5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_50  \n",
       "0     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "1     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "2     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "3     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "4     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "...                                                 ...  \n",
       "4995  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4996  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4997  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4998  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4999  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model alexcleu/wav2vec2-large-xlsr-polish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_folders(main_folder_path):\n",
    "    data = {}\n",
    "\n",
    "    for folder_name in os.listdir(main_folder_path):\n",
    "        folder_path = os.path.join(main_folder_path, folder_name)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "            data[folder_name] = file_paths\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_recordings_path = '.\\\\data\\\\mixed_recordings\\\\'\n",
    "snr_dataframe = create_dataframe_from_folders(mixed_recordings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_local</th>\n",
       "      <th>audiopath_project</th>\n",
       "      <th>noise_path</th>\n",
       "      <th>noise_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01818</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Jest także trzecia sprawa, która w czasie tej ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0457-00001</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dżuma  wziernik  przemianę  księdzu  krzywdzen...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0083-00007</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w piątek po południu była przesłuchiwana przez...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pwr-maleset-unk-train-0001-03097</td>\n",
       "      <td>pwr-maleset-unk</td>\n",
       "      <td>jeśli chcesz zostanę w domu</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pwr-maleset-unk-tra...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2862-00017</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Tekst nie opiera się na żadnych podstawach nau...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-2023-00011</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>Nareszcie zniecierpliwiony kazał zamurować okn...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mailabs-corpus_libr...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (249).wav</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0289-00016</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dostała  za  ten  reportaż  nagrodę  pulicera ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (172).wav</td>\n",
       "      <td>minibus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2846-00448</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Dotyczy ona zasadniczo dwóch kwestii</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\5 (164).wav</td>\n",
       "      <td>jeep_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0035-00018</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>każdy starał się odlecieć najbliższym samolote...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\6 (638).wav</td>\n",
       "      <td>truck_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0060-00012</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w tym roku zacznie się zaś budowa dodatkowych ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\8 (302).wav</td>\n",
       "      <td>other_car_interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname                     dataset  \\\n",
       "0     mozilla-common_voice_15-23-train-2856-01818  mozilla-common_voice_15-23   \n",
       "1         pjatk-clarin_studio-15-train-0457-00001      pjatk-clarin_studio-15   \n",
       "2         pjatk-clarin_mobile-15-train-0083-00007      pjatk-clarin_mobile-15   \n",
       "3                pwr-maleset-unk-train-0001-03097             pwr-maleset-unk   \n",
       "4     mozilla-common_voice_15-23-train-2862-00017  mozilla-common_voice_15-23   \n",
       "...                                           ...                         ...   \n",
       "4995  mailabs-corpus_librivox-19-train-2023-00011  mailabs-corpus_librivox-19   \n",
       "4996      pjatk-clarin_studio-15-train-0289-00016      pjatk-clarin_studio-15   \n",
       "4997  mozilla-common_voice_15-23-train-2846-00448  mozilla-common_voice_15-23   \n",
       "4998      pjatk-clarin_mobile-15-train-0035-00018      pjatk-clarin_mobile-15   \n",
       "4999      pjatk-clarin_mobile-15-train-0060-00012      pjatk-clarin_mobile-15   \n",
       "\n",
       "                                               ref_orig  sampling_rate  \\\n",
       "0     Jest także trzecia sprawa, która w czasie tej ...          16000   \n",
       "1     dżuma  wziernik  przemianę  księdzu  krzywdzen...          16000   \n",
       "2     w piątek po południu była przesłuchiwana przez...          16000   \n",
       "3                           jeśli chcesz zostanę w domu          16000   \n",
       "4     Tekst nie opiera się na żadnych podstawach nau...          16000   \n",
       "...                                                 ...            ...   \n",
       "4995  Nareszcie zniecierpliwiony kazał zamurować okn...          16000   \n",
       "4996  dostała  za  ten  reportaż  nagrodę  pulicera ...          16000   \n",
       "4997               Dotyczy ona zasadniczo dwóch kwestii          16000   \n",
       "4998  każdy starał się odlecieć najbliższym samolote...          16000   \n",
       "4999  w tym roku zacznie się zaś budowa dodatkowych ...          16000   \n",
       "\n",
       "                                        audiopath_local  \\\n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "...                                                 ...   \n",
       "4995  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4996  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4997  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4998  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4999  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "\n",
       "                                      audiopath_project  \\\n",
       "0     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "1     ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "2     ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "3     ./data/testing_batch/clear/pwr-maleset-unk-tra...   \n",
       "4     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "...                                                 ...   \n",
       "4995  ./data/testing_batch/clear/mailabs-corpus_libr...   \n",
       "4996  ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "4997  ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "4998  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "4999  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "\n",
       "                                             noise_path         noise_class  \n",
       "0      .\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav          jackhammer  \n",
       "1       .\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav               siren  \n",
       "2      .\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav          jackhammer  \n",
       "3     .\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav          jackhammer  \n",
       "4     .\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav            drilling  \n",
       "...                                                 ...                 ...  \n",
       "4995                .\\data\\VISC Dataset SON\\7 (249).wav  crossover_interior  \n",
       "4996                .\\data\\VISC Dataset SON\\2 (172).wav    minibus_interior  \n",
       "4997                .\\data\\VISC Dataset SON\\5 (164).wav       jeep_interior  \n",
       "4998                .\\data\\VISC Dataset SON\\6 (638).wav      truck_interior  \n",
       "4999                .\\data\\VISC Dataset SON\\8 (302).wav  other_car_interior  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dataframe['sentence'] = full_df['ref_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\configuration_utils.py:365: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m resampler \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(\u001b[38;5;241m48_000\u001b[39m, \u001b[38;5;241m16_000\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m snr_dataframe \u001b[38;5;241m=\u001b[39m snr_dataframe\u001b[38;5;241m.\u001b[39mmap(speech_file_to_array_fn)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(batch):\n\u001b[0;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m processor(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_SNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10455\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[1;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[0;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m  10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m> 10455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(infer)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10360\u001b[0m )\n\u001b[1;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10453\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m> 10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mspeech_file_to_array_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_file_to_array_fn\u001b[39m(batch):\n\u001b[1;32m----> 6\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(chars_to_ignore_regex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      8\u001b[0m     speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_SNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m resampler(speech_array)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "  \n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"SNR_100\"])\n",
    "  \n",
    "    batch[\"speech_SNR_100\"] = resampler(speech_array).squeeze().numpy()\n",
    "  \n",
    "    return batch\n",
    "\n",
    "wer = load_metric(\"wer\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model.to(\"cuda\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\;\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\“]'\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\n",
    "snr_dataframe = snr_dataframe.map(speech_file_to_array_fn)\n",
    "\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech_SNR_100\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "    \n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\n",
    "result = snr_dataframe.map(evaluate, batched=True, batch_size=8)\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model jonatasgrosman/wav2vec2-large-xlsr-53-polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid file: 0    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n1    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n2    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n3    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n4    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\nName: audiopath_local, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n\u001b[0;32m     15\u001b[0m df_test_wav \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 16\u001b[0m df_test_wav \u001b[38;5;241m=\u001b[39m speech_file_to_array_fn(df_whisper[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(df_test_wav[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m'\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m, in \u001b[0;36mspeech_file_to_array_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_file_to_array_fn\u001b[39m(batch):\n\u001b[1;32m---> 10\u001b[0m     speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudiopath_local\u001b[39m\u001b[38;5;124m\"\u001b[39m], sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m)\n\u001b[0;32m     11\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m speech_array\n\u001b[0;32m     12\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    211\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\soundfile.py:1212\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_virtual(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_virtual_io(file),\n\u001b[0;32m   1210\u001b[0m                                     mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, _ffi\u001b[38;5;241m.\u001b[39mNULL)\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid file: 0    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n1    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n2    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n3    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n4    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\nName: audiopath_local, dtype: object"
     ]
    }
   ],
   "source": [
    "\n",
    "LANG_ID = \"pl\"\n",
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-polish\"\n",
    "SAMPLES = 5\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"SNR100\"], sr=16_000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"ref_orig\"].upper()\n",
    "    return batch\n",
    "\n",
    "df_test_wav = pd.DataFrame()\n",
    "df_test_wav = speech_file_to_array_fn(df_whisper[0:5])\n",
    "inputs = processor(df_test_wav['speech'], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Reference:\", test_dataset[i][\"sentence\"])\n",
    "    print(\"Prediction:\", predicted_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
