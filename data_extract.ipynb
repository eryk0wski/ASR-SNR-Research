{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda_3\\envs\\ASR_Techmo\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from evaluate import load\n",
    "from data_engineering import create_distribution_dict, creating_random_split_df\n",
    "from audio_mixer import mixer\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading whole bigos v2 polish ASR dataset. WARNING, dataset contains ~80 GB od data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for amu-cai/pl-asr-bigos-v2 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/amu-cai/pl-asr-bigos-v2\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running script\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b241c5f8fd427b80e2c3b075d6f73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the dataset is already downloaded it just makes dictionary out downloaded data (approx. 10 seconds)\n",
    "data = load_dataset(\"amu-cai/pl-asr-bigos-v2\",'all', 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dictionary showing database distribution inside whole database, getting dataset names iterating by dict (faster version - 110 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fair-mls-20': 0.305,\n",
       " 'mozilla-common_voice_15-23': 0.233,\n",
       " 'mailabs-corpus_librivox-19': 0.144,\n",
       " 'pjatk-clarin_studio-15': 0.134,\n",
       " 'pwr-maleset-unk': 0.046,\n",
       " 'pjatk-clarin_mobile-15': 0.035,\n",
       " 'google-fleurs-22': 0.035,\n",
       " 'pwr-viu-unk': 0.026,\n",
       " 'pwr-azon_read-20': 0.022,\n",
       " 'pwr-shortwords-unk': 0.009,\n",
       " 'polyai-minds14-21': 0.006,\n",
       " 'pwr-azon_spont-20': 0.004}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iterating by Dataset dictionary to get datasets names\n",
    "\n",
    "datasets_list = []\n",
    "for i in trange(len(data['train'])):\n",
    "    datasets_list.append(data['train'][i]['dataset'])\n",
    "\n",
    "df_datasets_distribution = pd.DataFrame()\n",
    "df_datasets_distribution['datasets'] = datasets_list\n",
    "\n",
    "#creating dictionary showing database distribution inside whole database\n",
    "dict_dst = create_distribution_dict(df_datasets_distribution['datasets'])\n",
    "dict_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe from the training set with 2500 randomly chosen examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_testing = creating_random_split_df(data['train'], 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the distribution of each dataset in choosen test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fair-mls-20': 0.29,\n",
       " 'mozilla-common_voice_15-23': 0.247,\n",
       " 'mailabs-corpus_librivox-19': 0.145,\n",
       " 'pjatk-clarin_studio-15': 0.138,\n",
       " 'pwr-maleset-unk': 0.046,\n",
       " 'google-fleurs-22': 0.042,\n",
       " 'pjatk-clarin_mobile-15': 0.036,\n",
       " 'pwr-viu-unk': 0.026,\n",
       " 'pwr-azon_read-20': 0.015,\n",
       " 'pwr-shortwords-unk': 0.008,\n",
       " 'polyai-minds14-21': 0.004,\n",
       " 'pwr-azon_spont-20': 0.004}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_distribution_dict(df_model_testing['dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare to see distribution of sets from whole dataset and from our choosen batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>audio</th>\n",
       "      <th>samplingrate_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_bigos</th>\n",
       "      <th>audiopath_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0029-00026</td>\n",
       "      <td>train</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>29</td>\n",
       "      <td>malinda musiała stanowczo oznajmić że nie potr...</td>\n",
       "      <td>{'path': 'pjatk-clarin_mobile-15-train-0029-00...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>pjatk-clarin_mobile-15-train-0029-00026.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fair-mls-20-train-0024-00346</td>\n",
       "      <td>train</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>24</td>\n",
       "      <td>szczęśliwej podróży do widzenia wołał lord puc...</td>\n",
       "      <td>{'path': 'fair-mls-20-train-0024-00346.wav', '...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0024-00346.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-1002-00097</td>\n",
       "      <td>train</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>1002</td>\n",
       "      <td>Wreszcie machnął ręką i poszedł dalej może myś...</td>\n",
       "      <td>{'path': 'mailabs-corpus_librivox-19-train-100...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>mailabs-corpus_librivox-19-train-1002-00097.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-2019-00258</td>\n",
       "      <td>train</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>2019</td>\n",
       "      <td>Co do mnie przekonany jestem że uśpiono mnie z...</td>\n",
       "      <td>{'path': 'mailabs-corpus_librivox-19-train-201...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>mailabs-corpus_librivox-19-train-2019-00258.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-fleurs-22-train-0001-01189</td>\n",
       "      <td>train</td>\n",
       "      <td>google-fleurs-22</td>\n",
       "      <td>1</td>\n",
       "      <td>imprezy te standardowo trwają od trzech do sze...</td>\n",
       "      <td>{'path': 'google-fleurs-22-train-0001-01189.wa...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>google-fleurs-22-train-0001-01189.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-01283</td>\n",
       "      <td>train</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>2851</td>\n",
       "      <td>Przede wszystkim musimy trwać przy instrumenta...</td>\n",
       "      <td>{'path': 'mozilla-common_voice_15-23-train-285...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-01283.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2849-00111</td>\n",
       "      <td>train</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>2849</td>\n",
       "      <td>Tak rozstali się.</td>\n",
       "      <td>{'path': 'mozilla-common_voice_15-23-train-284...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>mozilla-common_voice_15-23-train-2849-00111.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>fair-mls-20-train-0024-05850</td>\n",
       "      <td>train</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>24</td>\n",
       "      <td>nie bój się pan oni go nie wypuszczą od siebie...</td>\n",
       "      <td>{'path': 'fair-mls-20-train-0024-05850.wav', '...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0024-05850.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0539-00019</td>\n",
       "      <td>train</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>539</td>\n",
       "      <td>my  mówimy  że  najlepiej  zadba  o  siebie  o...</td>\n",
       "      <td>{'path': 'pjatk-clarin_studio-15-train-0539-00...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>pjatk-clarin_studio-15-train-0539-00019.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>pwr-viu-unk-train-0001-00721</td>\n",
       "      <td>train</td>\n",
       "      <td>pwr-viu-unk</td>\n",
       "      <td></td>\n",
       "      <td>poprzednie słowo</td>\n",
       "      <td>{'path': 'pwr-viu-unk-train-0001-00721.wav', '...</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>pwr-viu-unk-train-0001-00721.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname  split  \\\n",
       "0         pjatk-clarin_mobile-15-train-0029-00026  train   \n",
       "1                    fair-mls-20-train-0024-00346  train   \n",
       "2     mailabs-corpus_librivox-19-train-1002-00097  train   \n",
       "3     mailabs-corpus_librivox-19-train-2019-00258  train   \n",
       "4               google-fleurs-22-train-0001-01189  train   \n",
       "...                                           ...    ...   \n",
       "2495  mozilla-common_voice_15-23-train-2851-01283  train   \n",
       "2496  mozilla-common_voice_15-23-train-2849-00111  train   \n",
       "2497                 fair-mls-20-train-0024-05850  train   \n",
       "2498      pjatk-clarin_studio-15-train-0539-00019  train   \n",
       "2499                 pwr-viu-unk-train-0001-00721  train   \n",
       "\n",
       "                         dataset speaker_id  \\\n",
       "0         pjatk-clarin_mobile-15         29   \n",
       "1                    fair-mls-20         24   \n",
       "2     mailabs-corpus_librivox-19       1002   \n",
       "3     mailabs-corpus_librivox-19       2019   \n",
       "4               google-fleurs-22          1   \n",
       "...                          ...        ...   \n",
       "2495  mozilla-common_voice_15-23       2851   \n",
       "2496  mozilla-common_voice_15-23       2849   \n",
       "2497                 fair-mls-20         24   \n",
       "2498      pjatk-clarin_studio-15        539   \n",
       "2499                 pwr-viu-unk              \n",
       "\n",
       "                                               ref_orig  \\\n",
       "0     malinda musiała stanowczo oznajmić że nie potr...   \n",
       "1     szczęśliwej podróży do widzenia wołał lord puc...   \n",
       "2     Wreszcie machnął ręką i poszedł dalej może myś...   \n",
       "3     Co do mnie przekonany jestem że uśpiono mnie z...   \n",
       "4     imprezy te standardowo trwają od trzech do sze...   \n",
       "...                                                 ...   \n",
       "2495  Przede wszystkim musimy trwać przy instrumenta...   \n",
       "2496                                  Tak rozstali się.   \n",
       "2497  nie bój się pan oni go nie wypuszczą od siebie...   \n",
       "2498  my  mówimy  że  najlepiej  zadba  o  siebie  o...   \n",
       "2499                                   poprzednie słowo   \n",
       "\n",
       "                                                  audio  samplingrate_orig  \\\n",
       "0     {'path': 'pjatk-clarin_mobile-15-train-0029-00...              16000   \n",
       "1     {'path': 'fair-mls-20-train-0024-00346.wav', '...              16000   \n",
       "2     {'path': 'mailabs-corpus_librivox-19-train-100...              16000   \n",
       "3     {'path': 'mailabs-corpus_librivox-19-train-201...              16000   \n",
       "4     {'path': 'google-fleurs-22-train-0001-01189.wa...              16000   \n",
       "...                                                 ...                ...   \n",
       "2495  {'path': 'mozilla-common_voice_15-23-train-285...              16000   \n",
       "2496  {'path': 'mozilla-common_voice_15-23-train-284...              16000   \n",
       "2497  {'path': 'fair-mls-20-train-0024-05850.wav', '...              16000   \n",
       "2498  {'path': 'pjatk-clarin_studio-15-train-0539-00...              16000   \n",
       "2499  {'path': 'pwr-viu-unk-train-0001-00721.wav', '...              16000   \n",
       "\n",
       "      sampling_rate                                  audiopath_bigos  \\\n",
       "0             16000      pjatk-clarin_mobile-15-train-0029-00026.wav   \n",
       "1             16000                 fair-mls-20-train-0024-00346.wav   \n",
       "2             16000  mailabs-corpus_librivox-19-train-1002-00097.wav   \n",
       "3             16000  mailabs-corpus_librivox-19-train-2019-00258.wav   \n",
       "4             16000            google-fleurs-22-train-0001-01189.wav   \n",
       "...             ...                                              ...   \n",
       "2495          16000  mozilla-common_voice_15-23-train-2851-01283.wav   \n",
       "2496          16000  mozilla-common_voice_15-23-train-2849-00111.wav   \n",
       "2497          16000                 fair-mls-20-train-0024-05850.wav   \n",
       "2498          16000      pjatk-clarin_studio-15-train-0539-00019.wav   \n",
       "2499          16000                 pwr-viu-unk-train-0001-00721.wav   \n",
       "\n",
       "                                        audiopath_local  \n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "...                                                 ...  \n",
       "2495  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "2496  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "2497  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "2498  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "2499  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...  \n",
       "\n",
       "[2500 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving audio dataframe to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_testing=df_model_testing[['audioname','dataset','ref_orig','sampling_rate','audiopath_bigos','audiopath_local']]\n",
    "#line commented not to overwrite accidentally\n",
    "#df_model_testing.to_parquet('./data/parquets/testing_batch.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UrbanSound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urban_sounds = pd.read_csv('./data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "df_urban_sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting classes that are not necessary, and leaving: dog_bark, air_conditioner, jackhammer, drilling\n",
    "df_urban_sounds = df_urban_sounds[~df_urban_sounds['classID'].isin([1, 2, 5, 6, 8, 9])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each class distributution:  {'dog_bark': 1000, 'air_conditioner': 1000, 'jackhammer': 1000, 'drilling': 1000}\n",
      "Length of the result UrbanNoises dataframe:  4000\n"
     ]
    }
   ],
   "source": [
    "print('Each class distributution: ',create_distribution_dict(df_urban_sounds['class'],False))\n",
    "print('Length of the result UrbanNoises dataframe: ',len(df_urban_sounds['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79089-0-0-106.wav</td>\n",
       "      <td>79089</td>\n",
       "      <td>62.664375</td>\n",
       "      <td>66.664375</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167750-4-1-0.wav</td>\n",
       "      <td>167750</td>\n",
       "      <td>14.330286</td>\n",
       "      <td>18.330286</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165039-7-5-0.wav</td>\n",
       "      <td>165039</td>\n",
       "      <td>64.924130</td>\n",
       "      <td>68.924130</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57320-0-0-22.wav</td>\n",
       "      <td>57320</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146709-0-0-20.wav</td>\n",
       "      <td>146709</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>194754-3-0-1.wav</td>\n",
       "      <td>194754</td>\n",
       "      <td>0.812357</td>\n",
       "      <td>4.812357</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>30206-7-0-1.wav</td>\n",
       "      <td>30206</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>46669-4-0-54.wav</td>\n",
       "      <td>46669</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>24364-4-0-0.wav</td>\n",
       "      <td>24364</td>\n",
       "      <td>0.633371</td>\n",
       "      <td>4.633371</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>148463-7-3-4.wav</td>\n",
       "      <td>148463</td>\n",
       "      <td>294.484445</td>\n",
       "      <td>298.484445</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0     79089-0-0-106.wav   79089   62.664375   66.664375         2     9   \n",
       "1      167750-4-1-0.wav  167750   14.330286   18.330286         1    10   \n",
       "2      165039-7-5-0.wav  165039   64.924130   68.924130         1     3   \n",
       "3      57320-0-0-22.wav   57320   11.000000   15.000000         2     1   \n",
       "4     146709-0-0-20.wav  146709   10.000000   14.000000         1     4   \n",
       "...                 ...     ...         ...         ...       ...   ...   \n",
       "1995   194754-3-0-1.wav  194754    0.812357    4.812357         1     7   \n",
       "1996    30206-7-0-1.wav   30206    0.500000    4.500000         1     6   \n",
       "1997   46669-4-0-54.wav   46669   27.000000   31.000000         1     1   \n",
       "1998    24364-4-0-0.wav   24364    0.633371    4.633371         1     6   \n",
       "1999   148463-7-3-4.wav  148463  294.484445  298.484445         2     4   \n",
       "\n",
       "      classID            class  \n",
       "0           0  air_conditioner  \n",
       "1           4         drilling  \n",
       "2           7       jackhammer  \n",
       "3           0  air_conditioner  \n",
       "4           0  air_conditioner  \n",
       "...       ...              ...  \n",
       "1995        3         dog_bark  \n",
       "1996        7       jackhammer  \n",
       "1997        4         drilling  \n",
       "1998        4         drilling  \n",
       "1999        7       jackhammer  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urban_sounds_2000 = creating_random_split_df(df_urban_sounds, 2000)\n",
    "df_urban_sounds_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating path to each file in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the file path\n",
    "def create_file_path(row, folder_path):\n",
    "    folder_number = row['fold']\n",
    "    file_name = row['slice_file_name']\n",
    "    file_path = os.path.join(folder_path, f'fold{folder_number}', file_name)\n",
    "    return file_path\n",
    "\n",
    "base_path = '.\\\\data\\\\UrbanSound8K\\\\audio\\\\'\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df_urban_sounds_2000['audio_path'] = df_urban_sounds_2000.apply(create_file_path, axis=1, folder_path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79089-0-0-106.wav</td>\n",
       "      <td>79089</td>\n",
       "      <td>62.664375</td>\n",
       "      <td>66.664375</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167750-4-1-0.wav</td>\n",
       "      <td>167750</td>\n",
       "      <td>14.330286</td>\n",
       "      <td>18.330286</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165039-7-5-0.wav</td>\n",
       "      <td>165039</td>\n",
       "      <td>64.924130</td>\n",
       "      <td>68.924130</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57320-0-0-22.wav</td>\n",
       "      <td>57320</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146709-0-0-20.wav</td>\n",
       "      <td>146709</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>194754-3-0-1.wav</td>\n",
       "      <td>194754</td>\n",
       "      <td>0.812357</td>\n",
       "      <td>4.812357</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold7\\194754-3-0-1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>30206-7-0-1.wav</td>\n",
       "      <td>30206</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold6\\30206-7-0-1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>46669-4-0-54.wav</td>\n",
       "      <td>46669</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\46669-4-0-54.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>24364-4-0-0.wav</td>\n",
       "      <td>24364</td>\n",
       "      <td>0.633371</td>\n",
       "      <td>4.633371</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>drilling</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold6\\24364-4-0-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>148463-7-3-4.wav</td>\n",
       "      <td>148463</td>\n",
       "      <td>294.484445</td>\n",
       "      <td>298.484445</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold4\\148463-7-3-4.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0     79089-0-0-106.wav   79089   62.664375   66.664375         2     9   \n",
       "1      167750-4-1-0.wav  167750   14.330286   18.330286         1    10   \n",
       "2      165039-7-5-0.wav  165039   64.924130   68.924130         1     3   \n",
       "3      57320-0-0-22.wav   57320   11.000000   15.000000         2     1   \n",
       "4     146709-0-0-20.wav  146709   10.000000   14.000000         1     4   \n",
       "...                 ...     ...         ...         ...       ...   ...   \n",
       "1995   194754-3-0-1.wav  194754    0.812357    4.812357         1     7   \n",
       "1996    30206-7-0-1.wav   30206    0.500000    4.500000         1     6   \n",
       "1997   46669-4-0-54.wav   46669   27.000000   31.000000         1     1   \n",
       "1998    24364-4-0-0.wav   24364    0.633371    4.633371         1     6   \n",
       "1999   148463-7-3-4.wav  148463  294.484445  298.484445         2     4   \n",
       "\n",
       "      classID            class  \\\n",
       "0           0  air_conditioner   \n",
       "1           4         drilling   \n",
       "2           7       jackhammer   \n",
       "3           0  air_conditioner   \n",
       "4           0  air_conditioner   \n",
       "...       ...              ...   \n",
       "1995        3         dog_bark   \n",
       "1996        7       jackhammer   \n",
       "1997        4         drilling   \n",
       "1998        4         drilling   \n",
       "1999        7       jackhammer   \n",
       "\n",
       "                                             audio_path  \n",
       "0     .\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav  \n",
       "1     .\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav  \n",
       "2      .\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav  \n",
       "3      .\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav  \n",
       "4     .\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav  \n",
       "...                                                 ...  \n",
       "1995   .\\data\\UrbanSound8K\\audio\\fold7\\194754-3-0-1.wav  \n",
       "1996    .\\data\\UrbanSound8K\\audio\\fold6\\30206-7-0-1.wav  \n",
       "1997   .\\data\\UrbanSound8K\\audio\\fold1\\46669-4-0-54.wav  \n",
       "1998    .\\data\\UrbanSound8K\\audio\\fold6\\24364-4-0-0.wav  \n",
       "1999   .\\data\\UrbanSound8K\\audio\\fold4\\148463-7-3-4.wav  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urban_sounds_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe from Vechicle Interior Sound folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "visc_folder_path = '.\\\\data\\\\VISC Dataset SON\\\\'\n",
    "\n",
    "file_paths = []\n",
    "class_ids = []\n",
    "\n",
    "\n",
    "# Traverse the directory\n",
    "for filename in os.listdir(visc_folder_path):\n",
    "    # Join the folder path with the filename to get the full file path\n",
    "    file_path = os.path.join(visc_folder_path, filename)\n",
    "    \n",
    "    # Extract the class ID from the file name\n",
    "    class_id = int(filename.split()[0])\n",
    "    \n",
    "    # Append the values to the lists\n",
    "    file_paths.append(file_path)\n",
    "    class_ids.append(class_id)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'file_path': file_paths, 'class_id': class_ids})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ading each noise class name to the dataframe as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "visc_noises_dataframe = creating_random_split_df(df,500)\n",
    "\n",
    "visc_noises_dict = {1 : 'bus_interior',\n",
    "                    2 : 'minibus_interior',\n",
    "                    3 : 'pickup_interior',\n",
    "                    4 : 'sports_car_interior',\n",
    "                    5 : 'jeep_interior',\n",
    "                    6 : 'truck_interior',\n",
    "                    7 : 'crossover_interior',\n",
    "                    8 : 'other_car_interior'}\n",
    "visc_noises_dataframe['class'] = visc_noises_dataframe['class_id'].map(visc_noises_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\5 (496).wav</td>\n",
       "      <td>5</td>\n",
       "      <td>jeep_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (522).wav</td>\n",
       "      <td>7</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (766).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\8 (624).wav</td>\n",
       "      <td>8</td>\n",
       "      <td>other_car_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (471).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\4 (36).wav</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_car_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (251).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (692).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (492).wav</td>\n",
       "      <td>2</td>\n",
       "      <td>minibus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (620).wav</td>\n",
       "      <td>7</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_path  class_id                class\n",
       "0    .\\data\\VISC Dataset SON\\5 (496).wav         5        jeep_interior\n",
       "1    .\\data\\VISC Dataset SON\\7 (522).wav         7   crossover_interior\n",
       "2    .\\data\\VISC Dataset SON\\1 (766).wav         1         bus_interior\n",
       "3    .\\data\\VISC Dataset SON\\8 (624).wav         8   other_car_interior\n",
       "4    .\\data\\VISC Dataset SON\\1 (471).wav         1         bus_interior\n",
       "..                                   ...       ...                  ...\n",
       "495   .\\data\\VISC Dataset SON\\4 (36).wav         4  sports_car_interior\n",
       "496  .\\data\\VISC Dataset SON\\1 (251).wav         1         bus_interior\n",
       "497  .\\data\\VISC Dataset SON\\1 (692).wav         1         bus_interior\n",
       "498  .\\data\\VISC Dataset SON\\2 (492).wav         2     minibus_interior\n",
       "499  .\\data\\VISC Dataset SON\\7 (620).wav         7   crossover_interior\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visc_noises_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating one dataframe with noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eryk\\AppData\\Local\\Temp\\ipykernel_4144\\511043167.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  urban_noises_df['file_path'] = urban_noises_df['audio_path']\n"
     ]
    }
   ],
   "source": [
    "visc_noises_df = visc_noises_dataframe[['file_path','class']]\n",
    "urban_noises_df = df_urban_sounds_2000[['audio_path','class']]\n",
    "urban_noises_df['file_path'] = urban_noises_df['audio_path']\n",
    "urban_noises_df_2 = urban_noises_df[['file_path','class']]\n",
    "noise_df = pd.concat([urban_noises_df_2,visc_noises_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving noise dataframe to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\4 (36).wav</td>\n",
       "      <td>sports_car_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (251).wav</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (692).wav</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (492).wav</td>\n",
       "      <td>minibus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (620).wav</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_path                class\n",
       "0     .\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav      air_conditioner\n",
       "1     .\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav             drilling\n",
       "2      .\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav           jackhammer\n",
       "3      .\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav      air_conditioner\n",
       "4     .\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav      air_conditioner\n",
       "...                                                 ...                  ...\n",
       "2495                 .\\data\\VISC Dataset SON\\4 (36).wav  sports_car_interior\n",
       "2496                .\\data\\VISC Dataset SON\\1 (251).wav         bus_interior\n",
       "2497                .\\data\\VISC Dataset SON\\1 (692).wav         bus_interior\n",
       "2498                .\\data\\VISC Dataset SON\\2 (492).wav     minibus_interior\n",
       "2499                .\\data\\VISC Dataset SON\\7 (620).wav   crossover_interior\n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_df.to_parquet('./data/parquets/noise_df.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating one dataframe with everything combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio= pd.read_parquet('./data/parquets/testing_batch.parquet.gzip') \n",
    "df_noises = pd.read_parquet('./data/parquets/noise_df.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_bigos</th>\n",
       "      <th>audiopath_local</th>\n",
       "      <th>noise_path</th>\n",
       "      <th>noise_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair-mls-20-train-0009-04739</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>tam nocne włóczęgi wołano z dachów jeżeli nie ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0009-04739.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0488-00003</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>w  pracy  studenci  chcieliby  przede  wszystk...</td>\n",
       "      <td>16000</td>\n",
       "      <td>pjatk-clarin_studio-15-train-0488-00003.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair-mls-20-train-0009-05501</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>co to znaczy sam siebie zapytywał faraon czy g...</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0009-05501.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fair-mls-20-train-0021-01519</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0021-01519.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0335-00001</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>zaokrągla  uziemienie  księdzu  liźnięcie  rol...</td>\n",
       "      <td>16000</td>\n",
       "      <td>pjatk-clarin_studio-15-train-0335-00001.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>fair-mls-20-train-0009-06517</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyzn w państw...</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0009-06517.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\4 (36).wav</td>\n",
       "      <td>sports_car_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-00218</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>W odniesieniu do Lizbony, uczyniliśmy także po...</td>\n",
       "      <td>16000</td>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-00218.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (251).wav</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01361</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Jej budżet to budżet, który wspiera inwestycje</td>\n",
       "      <td>16000</td>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01361.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\1 (692).wav</td>\n",
       "      <td>bus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>fair-mls-20-train-0009-03165</td>\n",
       "      <td>fair-mls-20</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>fair-mls-20-train-0009-03165.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (492).wav</td>\n",
       "      <td>minibus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2850-00179</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Prywatyzacja usług publicznych i społecznych r...</td>\n",
       "      <td>16000</td>\n",
       "      <td>mozilla-common_voice_15-23-train-2850-00179.wav</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (620).wav</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname                     dataset  \\\n",
       "0                    fair-mls-20-train-0009-04739                 fair-mls-20   \n",
       "1         pjatk-clarin_studio-15-train-0488-00003      pjatk-clarin_studio-15   \n",
       "2                    fair-mls-20-train-0009-05501                 fair-mls-20   \n",
       "3                    fair-mls-20-train-0021-01519                 fair-mls-20   \n",
       "4         pjatk-clarin_studio-15-train-0335-00001      pjatk-clarin_studio-15   \n",
       "...                                           ...                         ...   \n",
       "2495                 fair-mls-20-train-0009-06517                 fair-mls-20   \n",
       "2496  mozilla-common_voice_15-23-train-2851-00218  mozilla-common_voice_15-23   \n",
       "2497  mozilla-common_voice_15-23-train-2856-01361  mozilla-common_voice_15-23   \n",
       "2498                 fair-mls-20-train-0009-03165                 fair-mls-20   \n",
       "2499  mozilla-common_voice_15-23-train-2850-00179  mozilla-common_voice_15-23   \n",
       "\n",
       "                                               ref_orig  sampling_rate  \\\n",
       "0     tam nocne włóczęgi wołano z dachów jeżeli nie ...          16000   \n",
       "1     w  pracy  studenci  chcieliby  przede  wszystk...          16000   \n",
       "2     co to znaczy sam siebie zapytywał faraon czy g...          16000   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...          16000   \n",
       "4     zaokrągla  uziemienie  księdzu  liźnięcie  rol...          16000   \n",
       "...                                                 ...            ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyzn w państw...          16000   \n",
       "2496  W odniesieniu do Lizbony, uczyniliśmy także po...          16000   \n",
       "2497     Jej budżet to budżet, który wspiera inwestycje          16000   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...          16000   \n",
       "2499  Prywatyzacja usług publicznych i społecznych r...          16000   \n",
       "\n",
       "                                      audiopath_bigos  \\\n",
       "0                    fair-mls-20-train-0009-04739.wav   \n",
       "1         pjatk-clarin_studio-15-train-0488-00003.wav   \n",
       "2                    fair-mls-20-train-0009-05501.wav   \n",
       "3                    fair-mls-20-train-0021-01519.wav   \n",
       "4         pjatk-clarin_studio-15-train-0335-00001.wav   \n",
       "...                                               ...   \n",
       "2495                 fair-mls-20-train-0009-06517.wav   \n",
       "2496  mozilla-common_voice_15-23-train-2851-00218.wav   \n",
       "2497  mozilla-common_voice_15-23-train-2856-01361.wav   \n",
       "2498                 fair-mls-20-train-0009-03165.wav   \n",
       "2499  mozilla-common_voice_15-23-train-2850-00179.wav   \n",
       "\n",
       "                                        audiopath_local  \\\n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "...                                                 ...   \n",
       "2495  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2496  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2497  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2498  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2499  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "\n",
       "                                             noise_path          noise_class  \n",
       "0     .\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav      air_conditioner  \n",
       "1     .\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav             drilling  \n",
       "2      .\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav           jackhammer  \n",
       "3      .\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav      air_conditioner  \n",
       "4     .\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav      air_conditioner  \n",
       "...                                                 ...                  ...  \n",
       "2495                 .\\data\\VISC Dataset SON\\4 (36).wav  sports_car_interior  \n",
       "2496                .\\data\\VISC Dataset SON\\1 (251).wav         bus_interior  \n",
       "2497                .\\data\\VISC Dataset SON\\1 (692).wav         bus_interior  \n",
       "2498                .\\data\\VISC Dataset SON\\2 (492).wav     minibus_interior  \n",
       "2499                .\\data\\VISC Dataset SON\\7 (620).wav   crossover_interior  \n",
       "\n",
       "[2500 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio['noise_path'] = df_noises['file_path']\n",
    "df_audio['noise_class'] = df_noises['class']\n",
    "df_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising noise loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_loudness(file_paths, target_loudness=-15.0, output_folder=\"normalized\", normalization_type=\"mean\"):\n",
    "    normalized_file_paths = []  # List to store paths of normalized files\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load audio files and calculate loudness\n",
    "    audio_segments = [AudioSegment.from_file(file_path) for file_path in file_paths]\n",
    "    loudness_levels = [segment.dBFS for segment in audio_segments]\n",
    "\n",
    "    # Calculate the normalization factor based on mean or median loudness\n",
    "    if normalization_type == \"mean\":\n",
    "        normalization_factor = target_loudness - sum(loudness_levels) / len(loudness_levels)\n",
    "    elif normalization_type == \"median\":\n",
    "        sorted_loudness = sorted(loudness_levels)\n",
    "        middle_index = len(sorted_loudness) // 2\n",
    "        normalization_factor = target_loudness - sorted_loudness[middle_index]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization type. Use 'mean' or 'median'.\")\n",
    "\n",
    "    # Normalize each audio file\n",
    "    normalized_segments = [segment + normalization_factor for segment in audio_segments]\n",
    "\n",
    "    # Export normalized audio files to the output folder with the same names\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        file_name = os.path.basename(file_path)  # Extract file name from path\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        normalized_segments[i].export(output_path, format=\"wav\")\n",
    "        normalized_file_paths.append(output_path)  # Append output path to the list\n",
    "    \n",
    "    print(\"Normalization completed. Normalized files saved in:\", output_folder)\n",
    "\n",
    "    return normalized_file_paths  # Return the list of normalized file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minuss_15db\n"
     ]
    }
   ],
   "source": [
    "#laptop\n",
    "folder_path = './data/example_SNR_audio/'\n",
    "file_paths = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):  # Adjust this condition based on your file format\n",
    "        audio_file = os.path.join(folder_path, filename)\n",
    "        file_paths.append(audio_file)\n",
    "\n",
    "\n",
    "output_folder = \"./data/mixed_recordings/normalised_recordings/minuss_15db\"\n",
    "normalize_loudness(file_paths, output_folder=output_folder,normalization_type=\"mean\",target_loudness=-15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/plus_15db\n"
     ]
    }
   ],
   "source": [
    "file_paths = df_audio['noise_path'].to_list()\n",
    "output_folder = \"./data/mixed_recordings/normalised_recordings/minuss_15db\"\n",
    "normalize_loudness(file_paths, output_folder=output_folder,normalization_type=\"mean\",target_loudness=-15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-15dBmed/\n",
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-20dBmed/\n",
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-25dBmed/\n",
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-30dBmed/\n",
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-35dBmed/\n",
      "Normalization completed. Normalized files saved in: ./data/mixed_recordings/normalised_recordings/minus_-40dBmed/\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "file_paths = df_audio['noise_path'].to_list()\n",
    "loudnesses = [-15, -20, -25, -30, -35, -40]\n",
    "for loudness in loudnesses:\n",
    "    output_folder = \"./data/mixed_recordings/normalised_recordings/minus_\" + str(loudness) +  \"dBmed/\"\n",
    "    normalize_loudness(file_paths, output_folder=output_folder,normalization_type=\"median\",target_loudness=-loudness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking loudness of the files to check if function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "def loudness_function(file_path):\n",
    "    data,rate = sf.read(file_path)\n",
    "    meter = pyln.Meter(rate)\n",
    "    loudness = meter.integrated_loudness(data)\n",
    "    return loudness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: .\\data\\UrbanSound8K\\audio\\fold9\\79089-0-0-106.wav, Mean Loudness: 0.10479561239480972 dB\n",
      "File: .\\data\\UrbanSound8K\\audio\\fold10\\167750-4-1-0.wav, Mean Loudness: 0.044091030955314636 dB\n",
      "File: .\\data\\UrbanSound8K\\audio\\fold3\\165039-7-5-0.wav, Mean Loudness: 0.0692070722579956 dB\n",
      "File: .\\data\\UrbanSound8K\\audio\\fold1\\57320-0-0-22.wav, Mean Loudness: 0.0559232197701931 dB\n",
      "File: .\\data\\UrbanSound8K\\audio\\fold4\\146709-0-0-20.wav, Mean Loudness: 0.048664987087249756 dB\n",
      "File: .\\data\\UrbanSound8K\\audio\\fold1\\180937-7-1-1.wav, Mean Loudness: 0.09412972629070282 dB\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "for file in file_paths[0:6]:\n",
    "        mean_loudness = calculate_mean_loudness(file)\n",
    "        print(f\"File: {file}, Mean Loudness: {mean_loudness} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 0.001_SNR_audio_file.wav, Mean Loudness: 0.04850560426712036 dB, Peak Loudness: 0.11297627538442612\n",
      "\n",
      " Loudness: -28.5842880026989\n",
      "File: 0.01_SNR_audio_file.wav, Mean Loudness: 0.04847461357712746 dB, Peak Loudness: 0.11296653002500534\n",
      "\n",
      " Loudness: -28.586210046899303\n",
      "File: 0.1_SNR_audio_file.wav, Mean Loudness: 0.04816778004169464 dB, Peak Loudness: 0.11286386847496033\n",
      "\n",
      " Loudness: -28.60509540219031\n",
      "File: 10_SNR_audio_file.wav, Mean Loudness: 0.030357489362359047 dB, Peak Loudness: 0.10818291455507278\n",
      "\n",
      " Loudness: -28.474650109399008\n",
      "File: 120_SNR_audio_file.wav, Mean Loudness: 0.025161296129226685 dB, Peak Loudness: 0.10743813216686249\n",
      "\n",
      " Loudness: -28.418271985405184\n",
      "File: 1_SNR_audio_file.wav, Mean Loudness: 0.04530452936887741 dB, Peak Loudness: 0.1119380071759224\n",
      "\n",
      " Loudness: -28.77752098863526\n",
      "File: 30_SNR_audio_file.wav, Mean Loudness: 0.025377176702022552 dB, Peak Loudness: 0.10746891051530838\n",
      "\n",
      " Loudness: -28.485211453144498\n",
      "File: 55_SNR_audio_file.wav, Mean Loudness: 0.025162572041153908 dB, Peak Loudness: 0.10743885487318039\n",
      "\n",
      " Loudness: -28.418370302215866\n",
      "File: 88_SNR_audio_file.wav, Mean Loudness: 0.025161312893033028 dB, Peak Loudness: 0.10743807256221771\n",
      "\n",
      " Loudness: -28.418271350682872\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def calculate_loudness(audio_file):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Calculate the loudness using perceptual weighting (using ITU-R BS.1770)\n",
    "    loudness = librosa.feature.rms(y=y)\n",
    "\n",
    "    # Calculate the mean loudness\n",
    "    mean_loudness = loudness.mean()\n",
    "\n",
    "    # Calculate the peak loudness\n",
    "    peak_loudness = loudness.max()\n",
    "\n",
    "    return mean_loudness, peak_loudness\n",
    "\n",
    "# Example usage:\n",
    "folder_path = './data/example_SNR_audio/'\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):  # Adjust this condition based on your file format\n",
    "        audio_file = os.path.join(folder_path, filename)\n",
    "        mean_loudness,peak_loudness = calculate_loudness(audio_file)\n",
    "        print(f\"File: {filename}, Mean Loudness: {mean_loudness} dB, Peak Loudness: {peak_loudness}\")\n",
    "        loudnes = loudness_function(audio_file)\n",
    "        print(\"\\n Loudness:\",  loudnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 0.001_SNR_audio_file.wav, Mean Loudness: 0.20626680552959442 dB, Peak Loudness: 0.4655102789402008\n",
      "File: 0.01_SNR_audio_file.wav, Mean Loudness: 0.20613504946231842 dB, Peak Loudness: 0.4654773473739624\n",
      "File: 0.1_SNR_audio_file.wav, Mean Loudness: 0.2048298865556717 dB, Peak Loudness: 0.4651143550872803\n",
      "File: 10_SNR_audio_file.wav, Mean Loudness: 0.1289665549993515 dB, Peak Loudness: 0.4489797055721283\n",
      "File: 120_SNR_audio_file.wav, Mean Loudness: 0.10676495730876923 dB, Peak Loudness: 0.44644665718078613\n",
      "File: 1_SNR_audio_file.wav, Mean Loudness: 0.19264642894268036 dB, Peak Loudness: 0.46185845136642456\n",
      "File: 30_SNR_audio_file.wav, Mean Loudness: 0.10768909752368927 dB, Peak Loudness: 0.4465368688106537\n",
      "File: 55_SNR_audio_file.wav, Mean Loudness: 0.10677050799131393 dB, Peak Loudness: 0.4464489817619324\n",
      "File: 88_SNR_audio_file.wav, Mean Loudness: 0.1067650243639946 dB, Peak Loudness: 0.44644641876220703\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./data/mixed_recordings/normalised_recordings/minuss_15db\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):  # Adjust this condition based on your file format\n",
    "        audio_file = os.path.join(folder_path, filename)\n",
    "        mean_loudness,peak_loudness = calculate_loudness(audio_file)\n",
    "        print(f\"File: {filename}, Mean Loudness: {mean_loudness} dB, Peak Loudness: {peak_loudness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating folders with mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_values = [-3, -5, -10, -15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through each SNR value\n",
    "for snr in snr_values:\n",
    "    # Create a folder for the current SNR value\n",
    "    folder_path = f'./data/mixed_recordings/SNR_{snr}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Loop through the dataframe and mix files for the current SNR value\n",
    "    for index, row in full_df.iterrows():\n",
    "        signal_path = row['audiopath_local']\n",
    "        noise_path = row['noise_path']\n",
    "        audio_name = row['audioname'] + '.wav'\n",
    "        save_path = os.path.join(folder_path, audio_name)  # Change the naming convention if needed\n",
    "\n",
    "        # Call your mixer function here\n",
    "        mixer(signal_path, noise_path, snr, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model bark whisper v3 Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# Specify the CUDA device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "torch_dtype = torch.float32  # You can adjust the dtype if needed\n",
    "\n",
    "# Load model and move it to CUDA\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create the pipeline with CUDA support\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2451d8586c964645a6fb2c754dff8920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "#whisper_results = []\n",
    "#for i in range(len(df_whisper)):\n",
    "#    sample = df_whisper['audiopath_local'][i]\n",
    "#    result = pipe(sample)\n",
    "#    whisper_results.append(result['text'])\n",
    "\n",
    "#df_whisper['whisper_pred'] = whisper_results\n",
    "results = []\n",
    "\n",
    "for i in trange(len(snr_df)):\n",
    "    sample = snr_dataframe['SNR_-3'][i]\n",
    "    result = pipe(sample, generate_kwargs={\"language\": \"polish\"})\n",
    "    results.append(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['whisper_SNR_-3'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.71195991245705\n"
     ]
    }
   ],
   "source": [
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=full_df['whisper_SNR_50'], references=full_df['ref_orig'])\n",
    "print(wer_score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_parquet('full_testing_df.parquet.gzip', compression = 'gzip')\n",
    "#snr_df.to_parquet('snr_dataframe.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('full_testing_df.parquet.gzip') \n",
    "snr_df = pd.read_parquet('snr_dataframe.parquet.gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_local</th>\n",
       "      <th>audiopath_project</th>\n",
       "      <th>noise_path</th>\n",
       "      <th>noise_class</th>\n",
       "      <th>whisper_no_noise</th>\n",
       "      <th>whisper_SNR_100</th>\n",
       "      <th>whisper_SNR_10</th>\n",
       "      <th>whisper_SNR_1</th>\n",
       "      <th>audiofile_mixed</th>\n",
       "      <th>whisper_SNR_-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01818</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Jest także trzecia sprawa, która w czasie tej ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>Jest także trzecia sprawa, która w czasie tej...</td>\n",
       "      <td>rycerze moi współbracia boleśni bardzośmy mał...</td>\n",
       "      <td>Rycerze moi, współbracia boleśni, Bardzośmy m...</td>\n",
       "      <td>Rycerze moi, współbracia boleśni, Bardzośmy m...</td>\n",
       "      <td>fair-mls-20-train-0009-00038</td>\n",
       "      <td>Rycerze moi, współbracia boleśni, Bardzośmy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0457-00001</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dżuma  wziernik  przemianę  księdzu  krzywdzen...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>Dżuma, wziernik, przemianę, księdzu, krzywdze...</td>\n",
       "      <td>kantor choć guza dostał wpośród czoła gdy pos...</td>\n",
       "      <td>Kantor, choć guza dostał w pośród czoła, gdy ...</td>\n",
       "      <td>Kantor, choć guza dostał w pośród czoła, gdy ...</td>\n",
       "      <td>fair-mls-20-train-0009-00044</td>\n",
       "      <td>Kantor, choć guza dostał w pośród czoła, gdy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0083-00007</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w piątek po południu była przesłuchiwana przez...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>w piątek po południu była przesłuchiwana prze...</td>\n",
       "      <td>przeszłe przypadki gdy dobrze pamięta zmyśla ...</td>\n",
       "      <td>Przeszłe przypadki, gdy dobrze pamięta Zmyśla...</td>\n",
       "      <td>Przeszły przypadki, gdy dobrze pamięta, Myśla...</td>\n",
       "      <td>fair-mls-20-train-0009-00067</td>\n",
       "      <td>Przeszło przypadki, gdy dobrze pamięta, myśli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pwr-maleset-unk-train-0001-03097</td>\n",
       "      <td>pwr-maleset-unk</td>\n",
       "      <td>jeśli chcesz zostanę w domu</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pwr-maleset-unk-tra...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>Jeśli chcesz zostanę w domu.</td>\n",
       "      <td>nie przykrzy własnym hołdownikom ani swemu mo...</td>\n",
       "      <td>nie przykrzy własnym hołdownikom ani swemu mo...</td>\n",
       "      <td>nie przykrzy własnym hołdownikom ani swemu mo...</td>\n",
       "      <td>fair-mls-20-train-0009-00079</td>\n",
       "      <td>Nie przykrzy własnym hołdownikom, Ani swemu m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2862-00017</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Tekst nie opiera się na żadnych podstawach nau...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav</td>\n",
       "      <td>drilling</td>\n",
       "      <td>Tekst nie opiera się na żadnych podstawach na...</td>\n",
       "      <td>pięknież to przecie patrzeć na świat z góry w...</td>\n",
       "      <td>Pięknież to przecie patrzeć na świat z góry, ...</td>\n",
       "      <td>Pięknież to przecie patrzyć na świat z góry, ...</td>\n",
       "      <td>fair-mls-20-train-0009-00080</td>\n",
       "      <td>Piękny, że to przecie patrzyć na świat z góry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-2023-00011</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>Nareszcie zniecierpliwiony kazał zamurować okn...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mailabs-corpus_libr...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (249).wav</td>\n",
       "      <td>crossover_interior</td>\n",
       "      <td>Nareszcie zniecierpliwiony kazał zamurować ok...</td>\n",
       "      <td>Duże litery.</td>\n",
       "      <td>Duże litery.</td>\n",
       "      <td>W tłu że litery.</td>\n",
       "      <td>pwr-viu-unk-train-0001-04231</td>\n",
       "      <td>Służę literę.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0289-00016</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dostała  za  ten  reportaż  nagrodę  pulicera ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (172).wav</td>\n",
       "      <td>minibus_interior</td>\n",
       "      <td>Dostała zatem reportaż nagrodę Pulitzera, ale...</td>\n",
       "      <td>Duże litery.</td>\n",
       "      <td>Duże litery.</td>\n",
       "      <td>Duże litery.</td>\n",
       "      <td>pwr-viu-unk-train-0001-04241</td>\n",
       "      <td>Duże litery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2846-00448</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Dotyczy ona zasadniczo dwóch kwestii</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\5 (164).wav</td>\n",
       "      <td>jeep_interior</td>\n",
       "      <td>Dotyczy ona zasadniczo dwóch kwestii.</td>\n",
       "      <td>Małe litery.</td>\n",
       "      <td>Małe litery.</td>\n",
       "      <td>mała litarz</td>\n",
       "      <td>pwr-viu-unk-train-0001-04251</td>\n",
       "      <td>Mała literka.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0035-00018</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>każdy starał się odlecieć najbliższym samolote...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\6 (638).wav</td>\n",
       "      <td>truck_interior</td>\n",
       "      <td>Każdy starał się odjechać najbliższym samolot...</td>\n",
       "      <td>Małe litele.</td>\n",
       "      <td>Mała Litera</td>\n",
       "      <td>Mało mi wcale.</td>\n",
       "      <td>pwr-viu-unk-train-0001-04261</td>\n",
       "      <td>Mało mi tego.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0060-00012</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w tym roku zacznie się zaś budowa dodatkowych ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\8 (302).wav</td>\n",
       "      <td>other_car_interior</td>\n",
       "      <td>W tym roku zacznie się zaś budowa dodatkowych...</td>\n",
       "      <td>Małe litery.</td>\n",
       "      <td>Małe litery.</td>\n",
       "      <td>Mała literka.</td>\n",
       "      <td>pwr-viu-unk-train-0001-04267</td>\n",
       "      <td>Mała literka.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname                     dataset  \\\n",
       "0     mozilla-common_voice_15-23-train-2856-01818  mozilla-common_voice_15-23   \n",
       "1         pjatk-clarin_studio-15-train-0457-00001      pjatk-clarin_studio-15   \n",
       "2         pjatk-clarin_mobile-15-train-0083-00007      pjatk-clarin_mobile-15   \n",
       "3                pwr-maleset-unk-train-0001-03097             pwr-maleset-unk   \n",
       "4     mozilla-common_voice_15-23-train-2862-00017  mozilla-common_voice_15-23   \n",
       "...                                           ...                         ...   \n",
       "4995  mailabs-corpus_librivox-19-train-2023-00011  mailabs-corpus_librivox-19   \n",
       "4996      pjatk-clarin_studio-15-train-0289-00016      pjatk-clarin_studio-15   \n",
       "4997  mozilla-common_voice_15-23-train-2846-00448  mozilla-common_voice_15-23   \n",
       "4998      pjatk-clarin_mobile-15-train-0035-00018      pjatk-clarin_mobile-15   \n",
       "4999      pjatk-clarin_mobile-15-train-0060-00012      pjatk-clarin_mobile-15   \n",
       "\n",
       "                                               ref_orig  sampling_rate  \\\n",
       "0     Jest także trzecia sprawa, która w czasie tej ...          16000   \n",
       "1     dżuma  wziernik  przemianę  księdzu  krzywdzen...          16000   \n",
       "2     w piątek po południu była przesłuchiwana przez...          16000   \n",
       "3                           jeśli chcesz zostanę w domu          16000   \n",
       "4     Tekst nie opiera się na żadnych podstawach nau...          16000   \n",
       "...                                                 ...            ...   \n",
       "4995  Nareszcie zniecierpliwiony kazał zamurować okn...          16000   \n",
       "4996  dostała  za  ten  reportaż  nagrodę  pulicera ...          16000   \n",
       "4997               Dotyczy ona zasadniczo dwóch kwestii          16000   \n",
       "4998  każdy starał się odlecieć najbliższym samolote...          16000   \n",
       "4999  w tym roku zacznie się zaś budowa dodatkowych ...          16000   \n",
       "\n",
       "                                        audiopath_local  \\\n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "...                                                 ...   \n",
       "4995  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4996  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4997  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4998  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4999  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "\n",
       "                                      audiopath_project  \\\n",
       "0     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "1     ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "2     ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "3     ./data/testing_batch/clear/pwr-maleset-unk-tra...   \n",
       "4     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "...                                                 ...   \n",
       "4995  ./data/testing_batch/clear/mailabs-corpus_libr...   \n",
       "4996  ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "4997  ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "4998  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "4999  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "\n",
       "                                             noise_path         noise_class  \\\n",
       "0      .\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav          jackhammer   \n",
       "1       .\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav               siren   \n",
       "2      .\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav          jackhammer   \n",
       "3     .\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav          jackhammer   \n",
       "4     .\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav            drilling   \n",
       "...                                                 ...                 ...   \n",
       "4995                .\\data\\VISC Dataset SON\\7 (249).wav  crossover_interior   \n",
       "4996                .\\data\\VISC Dataset SON\\2 (172).wav    minibus_interior   \n",
       "4997                .\\data\\VISC Dataset SON\\5 (164).wav       jeep_interior   \n",
       "4998                .\\data\\VISC Dataset SON\\6 (638).wav      truck_interior   \n",
       "4999                .\\data\\VISC Dataset SON\\8 (302).wav  other_car_interior   \n",
       "\n",
       "                                       whisper_no_noise  \\\n",
       "0      Jest także trzecia sprawa, która w czasie tej...   \n",
       "1      Dżuma, wziernik, przemianę, księdzu, krzywdze...   \n",
       "2      w piątek po południu była przesłuchiwana prze...   \n",
       "3                          Jeśli chcesz zostanę w domu.   \n",
       "4      Tekst nie opiera się na żadnych podstawach na...   \n",
       "...                                                 ...   \n",
       "4995   Nareszcie zniecierpliwiony kazał zamurować ok...   \n",
       "4996   Dostała zatem reportaż nagrodę Pulitzera, ale...   \n",
       "4997              Dotyczy ona zasadniczo dwóch kwestii.   \n",
       "4998   Każdy starał się odjechać najbliższym samolot...   \n",
       "4999   W tym roku zacznie się zaś budowa dodatkowych...   \n",
       "\n",
       "                                        whisper_SNR_100  \\\n",
       "0      rycerze moi współbracia boleśni bardzośmy mał...   \n",
       "1      kantor choć guza dostał wpośród czoła gdy pos...   \n",
       "2      przeszłe przypadki gdy dobrze pamięta zmyśla ...   \n",
       "3      nie przykrzy własnym hołdownikom ani swemu mo...   \n",
       "4      pięknież to przecie patrzeć na świat z góry w...   \n",
       "...                                                 ...   \n",
       "4995                                       Duże litery.   \n",
       "4996                                       Duże litery.   \n",
       "4997                                       Małe litery.   \n",
       "4998                                       Małe litele.   \n",
       "4999                                       Małe litery.   \n",
       "\n",
       "                                         whisper_SNR_10  \\\n",
       "0      Rycerze moi, współbracia boleśni, Bardzośmy m...   \n",
       "1      Kantor, choć guza dostał w pośród czoła, gdy ...   \n",
       "2      Przeszłe przypadki, gdy dobrze pamięta Zmyśla...   \n",
       "3      nie przykrzy własnym hołdownikom ani swemu mo...   \n",
       "4      Pięknież to przecie patrzeć na świat z góry, ...   \n",
       "...                                                 ...   \n",
       "4995                                       Duże litery.   \n",
       "4996                                       Duże litery.   \n",
       "4997                                       Małe litery.   \n",
       "4998                                        Mała Litera   \n",
       "4999                                       Małe litery.   \n",
       "\n",
       "                                          whisper_SNR_1  \\\n",
       "0      Rycerze moi, współbracia boleśni, Bardzośmy m...   \n",
       "1      Kantor, choć guza dostał w pośród czoła, gdy ...   \n",
       "2      Przeszły przypadki, gdy dobrze pamięta, Myśla...   \n",
       "3      nie przykrzy własnym hołdownikom ani swemu mo...   \n",
       "4      Pięknież to przecie patrzyć na świat z góry, ...   \n",
       "...                                                 ...   \n",
       "4995                                   W tłu że litery.   \n",
       "4996                                       Duże litery.   \n",
       "4997                                        mała litarz   \n",
       "4998                                     Mało mi wcale.   \n",
       "4999                                      Mała literka.   \n",
       "\n",
       "                   audiofile_mixed  \\\n",
       "0     fair-mls-20-train-0009-00038   \n",
       "1     fair-mls-20-train-0009-00044   \n",
       "2     fair-mls-20-train-0009-00067   \n",
       "3     fair-mls-20-train-0009-00079   \n",
       "4     fair-mls-20-train-0009-00080   \n",
       "...                            ...   \n",
       "4995  pwr-viu-unk-train-0001-04231   \n",
       "4996  pwr-viu-unk-train-0001-04241   \n",
       "4997  pwr-viu-unk-train-0001-04251   \n",
       "4998  pwr-viu-unk-train-0001-04261   \n",
       "4999  pwr-viu-unk-train-0001-04267   \n",
       "\n",
       "                                         whisper_SNR_-3  \n",
       "0      Rycerze moi, współbracia boleśni, Bardzośmy m...  \n",
       "1      Kantor, choć guza dostał w pośród czoła, gdy ...  \n",
       "2      Przeszło przypadki, gdy dobrze pamięta, myśli...  \n",
       "3      Nie przykrzy własnym hołdownikom, Ani swemu m...  \n",
       "4      Piękny, że to przecie patrzyć na świat z góry...  \n",
       "...                                                 ...  \n",
       "4995                                      Służę literę.  \n",
       "4996                                       Duże litery.  \n",
       "4997                                      Mała literka.  \n",
       "4998                                      Mało mi tego.  \n",
       "4999                                      Mała literka.  \n",
       "\n",
       "[5000 rows x 14 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR_0.1</th>\n",
       "      <th>SNR_0.5</th>\n",
       "      <th>SNR_1</th>\n",
       "      <th>SNR_10</th>\n",
       "      <th>SNR_100</th>\n",
       "      <th>SNR_25</th>\n",
       "      <th>SNR_5</th>\n",
       "      <th>SNR_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SNR_0.1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                SNR_0.5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                  SNR_1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_10  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                SNR_100  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                 SNR_25  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                  SNR_5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_50  \n",
       "0     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "1     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "2     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "3     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "4     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "...                                                 ...  \n",
       "4995  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4996  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4997  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4998  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4999  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>audiofile_mixed</th>\n",
       "      <th>whisper_SNR_-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair-mls-20-train-0009-00038</td>\n",
       "      <td>rycerze moi współ bracia boleśni bardzośmy mał...</td>\n",
       "      <td>fair-mls-20-train-0009-00038</td>\n",
       "      <td>Rycerze moi, współbracia boleśni, Bardzośmy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fair-mls-20-train-0009-00044</td>\n",
       "      <td>kantor choć guza dostał wpośród czoła gdy post...</td>\n",
       "      <td>fair-mls-20-train-0009-00044</td>\n",
       "      <td>Kantor, choć guza dostał w pośród czoła, gdy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair-mls-20-train-0009-00067</td>\n",
       "      <td>przeszłe przypadki gdy dobrze pamięta zmyśla g...</td>\n",
       "      <td>fair-mls-20-train-0009-00067</td>\n",
       "      <td>Przeszło przypadki, gdy dobrze pamięta, myśli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fair-mls-20-train-0009-00079</td>\n",
       "      <td>nie przykrzy własnym hołdownikom ani swemu mon...</td>\n",
       "      <td>fair-mls-20-train-0009-00079</td>\n",
       "      <td>Nie przykrzy własnym hołdownikom, Ani swemu m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair-mls-20-train-0009-00080</td>\n",
       "      <td>nieskończenie pięknieżto przecie patrzać na św...</td>\n",
       "      <td>fair-mls-20-train-0009-00080</td>\n",
       "      <td>Piękny, że to przecie patrzyć na świat z góry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>pwr-viu-unk-train-0001-04231</td>\n",
       "      <td>duże litery</td>\n",
       "      <td>pwr-viu-unk-train-0001-04231</td>\n",
       "      <td>Służę literę.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>pwr-viu-unk-train-0001-04241</td>\n",
       "      <td>duże litery</td>\n",
       "      <td>pwr-viu-unk-train-0001-04241</td>\n",
       "      <td>Duże litery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>pwr-viu-unk-train-0001-04251</td>\n",
       "      <td>małe litery</td>\n",
       "      <td>pwr-viu-unk-train-0001-04251</td>\n",
       "      <td>Mała literka.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>pwr-viu-unk-train-0001-04261</td>\n",
       "      <td>małe litery</td>\n",
       "      <td>pwr-viu-unk-train-0001-04261</td>\n",
       "      <td>Mało mi tego.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>pwr-viu-unk-train-0001-04267</td>\n",
       "      <td>małe litery</td>\n",
       "      <td>pwr-viu-unk-train-0001-04267</td>\n",
       "      <td>Mała literka.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         audioname  \\\n",
       "0     fair-mls-20-train-0009-00038   \n",
       "1     fair-mls-20-train-0009-00044   \n",
       "2     fair-mls-20-train-0009-00067   \n",
       "3     fair-mls-20-train-0009-00079   \n",
       "4     fair-mls-20-train-0009-00080   \n",
       "...                            ...   \n",
       "4995  pwr-viu-unk-train-0001-04231   \n",
       "4996  pwr-viu-unk-train-0001-04241   \n",
       "4997  pwr-viu-unk-train-0001-04251   \n",
       "4998  pwr-viu-unk-train-0001-04261   \n",
       "4999  pwr-viu-unk-train-0001-04267   \n",
       "\n",
       "                                               ref_orig  \\\n",
       "0     rycerze moi współ bracia boleśni bardzośmy mał...   \n",
       "1     kantor choć guza dostał wpośród czoła gdy post...   \n",
       "2     przeszłe przypadki gdy dobrze pamięta zmyśla g...   \n",
       "3     nie przykrzy własnym hołdownikom ani swemu mon...   \n",
       "4     nieskończenie pięknieżto przecie patrzać na św...   \n",
       "...                                                 ...   \n",
       "4995                                        duże litery   \n",
       "4996                                        duże litery   \n",
       "4997                                        małe litery   \n",
       "4998                                        małe litery   \n",
       "4999                                        małe litery   \n",
       "\n",
       "                   audiofile_mixed  \\\n",
       "0     fair-mls-20-train-0009-00038   \n",
       "1     fair-mls-20-train-0009-00044   \n",
       "2     fair-mls-20-train-0009-00067   \n",
       "3     fair-mls-20-train-0009-00079   \n",
       "4     fair-mls-20-train-0009-00080   \n",
       "...                            ...   \n",
       "4995  pwr-viu-unk-train-0001-04231   \n",
       "4996  pwr-viu-unk-train-0001-04241   \n",
       "4997  pwr-viu-unk-train-0001-04251   \n",
       "4998  pwr-viu-unk-train-0001-04261   \n",
       "4999  pwr-viu-unk-train-0001-04267   \n",
       "\n",
       "                                         whisper_SNR_-3  \n",
       "0      Rycerze moi, współbracia boleśni, Bardzośmy m...  \n",
       "1      Kantor, choć guza dostał w pośród czoła, gdy ...  \n",
       "2      Przeszło przypadki, gdy dobrze pamięta, myśli...  \n",
       "3      Nie przykrzy własnym hołdownikom, Ani swemu m...  \n",
       "4      Piękny, że to przecie patrzyć na świat z góry...  \n",
       "...                                                 ...  \n",
       "4995                                      Służę literę.  \n",
       "4996                                       Duże litery.  \n",
       "4997                                      Mała literka.  \n",
       "4998                                      Mało mi tego.  \n",
       "4999                                      Mała literka.  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audioname = full_df[['audioname', 'ref_orig']]\n",
    "\n",
    "# Create a new dataframe for 'audiofile_mixed' and 'SNR_100'\n",
    "df_audiofile = full_df[['audiofile_mixed', 'whisper_SNR_-3']]\n",
    "\n",
    "# Merge the two dataframes on 'audioname' and 'audiofile_mixed'\n",
    "result_df = pd.merge(df_audioname, df_audiofile, how='outer', left_on='audioname', right_on='audiofile_mixed')\n",
    "\n",
    "# Drop the redundant column and rename columns\n",
    "#result_df = result_df.drop(columns=['audiofile_mixed']).rename(columns={'ref_orig': 'ref_orig', 'SNR_100': 'aligned_SNR_100'})\n",
    "\n",
    "# Display the result_df\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 47.315779\n"
     ]
    }
   ],
   "source": [
    "wer = load_metric('wer')\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result_df[\"whisper_SNR_-3\"], references=result_df[\"ref_orig\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       fair-mls-20-train-0009-00038\n",
      "1       fair-mls-20-train-0009-00044\n",
      "2       fair-mls-20-train-0009-00067\n",
      "3       fair-mls-20-train-0009-00079\n",
      "4       fair-mls-20-train-0009-00080\n",
      "                    ...             \n",
      "4995    pwr-viu-unk-train-0001-04231\n",
      "4996    pwr-viu-unk-train-0001-04241\n",
      "4997    pwr-viu-unk-train-0001-04251\n",
      "4998    pwr-viu-unk-train-0001-04261\n",
      "4999    pwr-viu-unk-train-0001-04267\n",
      "Name: audiofile, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_paths = snr_df['SNR_10']\n",
    "\n",
    "# Use the os.path.basename function to extract only the file name from each path\n",
    "snr_df['audiofile'] = file_paths.apply(lambda x: os.path.basename(x))\n",
    "snr_df['audiofile'] = snr_df['audiofile'].str.replace('.wav','')\n",
    "\n",
    "# Now df['file_name'] contains only the file names\n",
    "print(snr_df['audiofile'])\n",
    "\n",
    "full_df['audiofile_mixed'] = snr_df['audiofile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model alexcleu/wav2vec2-large-xlsr-polish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_folders(main_folder_path):\n",
    "    data = {}\n",
    "\n",
    "    for folder_name in os.listdir(main_folder_path):\n",
    "        folder_path = os.path.join(main_folder_path, folder_name)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "            data[folder_name] = file_paths\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_recordings_path = '.\\\\data\\\\mixed_recordings\\\\'\n",
    "snr_dataframe = create_dataframe_from_folders(mixed_recordings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR_-10</th>\n",
       "      <th>SNR_-15</th>\n",
       "      <th>SNR_-3</th>\n",
       "      <th>SNR_-5</th>\n",
       "      <th>SNR_0.1</th>\n",
       "      <th>SNR_0.5</th>\n",
       "      <th>SNR_1</th>\n",
       "      <th>SNR_10</th>\n",
       "      <th>SNR_100</th>\n",
       "      <th>SNR_25</th>\n",
       "      <th>SNR_5</th>\n",
       "      <th>SNR_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...</td>\n",
       "      <td>.\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SNR_-10  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_-10\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_-10\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                SNR_-15  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_-15\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_-15\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                 SNR_-3  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_-3\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_-3\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                 SNR_-5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_-5\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_-5\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                SNR_0.1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.1\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.1\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                SNR_0.5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_0.5\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_0.5\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                  SNR_1  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_1\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_1\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_10  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_10\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_10\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                SNR_100  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "1     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "2     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "3     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "4     .\\data\\mixed_recordings\\SNR_100\\fair-mls-20-tr...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_100\\pwr-viu-unk-tr...   \n",
       "\n",
       "                                                 SNR_25  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "1     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "2     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "3     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "4     .\\data\\mixed_recordings\\SNR_25\\fair-mls-20-tra...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_25\\pwr-viu-unk-tra...   \n",
       "\n",
       "                                                  SNR_5  \\\n",
       "0     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "1     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "2     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "3     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "4     .\\data\\mixed_recordings\\SNR_5\\fair-mls-20-trai...   \n",
       "...                                                 ...   \n",
       "4995  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4996  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4997  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4998  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "4999  .\\data\\mixed_recordings\\SNR_5\\pwr-viu-unk-trai...   \n",
       "\n",
       "                                                 SNR_50  \n",
       "0     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "1     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "2     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "3     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "4     .\\data\\mixed_recordings\\SNR_50\\fair-mls-20-tra...  \n",
       "...                                                 ...  \n",
       "4995  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4996  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4997  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4998  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "4999  .\\data\\mixed_recordings\\SNR_50\\pwr-viu-unk-tra...  \n",
       "\n",
       "[5000 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioname</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_orig</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>audiopath_local</th>\n",
       "      <th>audiopath_project</th>\n",
       "      <th>noise_path</th>\n",
       "      <th>noise_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01818</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Jest także trzecia sprawa, która w czasie tej ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0457-00001</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dżuma  wziernik  przemianę  księdzu  krzywdzen...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0083-00007</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w piątek po południu była przesłuchiwana przez...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pwr-maleset-unk-train-0001-03097</td>\n",
       "      <td>pwr-maleset-unk</td>\n",
       "      <td>jeśli chcesz zostanę w domu</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pwr-maleset-unk-tra...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2862-00017</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Tekst nie opiera się na żadnych podstawach nau...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>mailabs-corpus_librivox-19-train-2023-00011</td>\n",
       "      <td>mailabs-corpus_librivox-19</td>\n",
       "      <td>Nareszcie zniecierpliwiony kazał zamurować okn...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mailabs-corpus_libr...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\7 (249).wav</td>\n",
       "      <td>crossover_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0289-00016</td>\n",
       "      <td>pjatk-clarin_studio-15</td>\n",
       "      <td>dostała  za  ten  reportaż  nagrodę  pulicera ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_studio...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\2 (172).wav</td>\n",
       "      <td>minibus_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2846-00448</td>\n",
       "      <td>mozilla-common_voice_15-23</td>\n",
       "      <td>Dotyczy ona zasadniczo dwóch kwestii</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/mozilla-common_voic...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\5 (164).wav</td>\n",
       "      <td>jeep_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0035-00018</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>każdy starał się odlecieć najbliższym samolote...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\6 (638).wav</td>\n",
       "      <td>truck_interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>pjatk-clarin_mobile-15-train-0060-00012</td>\n",
       "      <td>pjatk-clarin_mobile-15</td>\n",
       "      <td>w tym roku zacznie się zaś budowa dodatkowych ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...</td>\n",
       "      <td>./data/testing_batch/clear/pjatk-clarin_mobile...</td>\n",
       "      <td>.\\data\\VISC Dataset SON\\8 (302).wav</td>\n",
       "      <td>other_car_interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audioname                     dataset  \\\n",
       "0     mozilla-common_voice_15-23-train-2856-01818  mozilla-common_voice_15-23   \n",
       "1         pjatk-clarin_studio-15-train-0457-00001      pjatk-clarin_studio-15   \n",
       "2         pjatk-clarin_mobile-15-train-0083-00007      pjatk-clarin_mobile-15   \n",
       "3                pwr-maleset-unk-train-0001-03097             pwr-maleset-unk   \n",
       "4     mozilla-common_voice_15-23-train-2862-00017  mozilla-common_voice_15-23   \n",
       "...                                           ...                         ...   \n",
       "4995  mailabs-corpus_librivox-19-train-2023-00011  mailabs-corpus_librivox-19   \n",
       "4996      pjatk-clarin_studio-15-train-0289-00016      pjatk-clarin_studio-15   \n",
       "4997  mozilla-common_voice_15-23-train-2846-00448  mozilla-common_voice_15-23   \n",
       "4998      pjatk-clarin_mobile-15-train-0035-00018      pjatk-clarin_mobile-15   \n",
       "4999      pjatk-clarin_mobile-15-train-0060-00012      pjatk-clarin_mobile-15   \n",
       "\n",
       "                                               ref_orig  sampling_rate  \\\n",
       "0     Jest także trzecia sprawa, która w czasie tej ...          16000   \n",
       "1     dżuma  wziernik  przemianę  księdzu  krzywdzen...          16000   \n",
       "2     w piątek po południu była przesłuchiwana przez...          16000   \n",
       "3                           jeśli chcesz zostanę w domu          16000   \n",
       "4     Tekst nie opiera się na żadnych podstawach nau...          16000   \n",
       "...                                                 ...            ...   \n",
       "4995  Nareszcie zniecierpliwiony kazał zamurować okn...          16000   \n",
       "4996  dostała  za  ten  reportaż  nagrodę  pulicera ...          16000   \n",
       "4997               Dotyczy ona zasadniczo dwóch kwestii          16000   \n",
       "4998  każdy starał się odlecieć najbliższym samolote...          16000   \n",
       "4999  w tym roku zacznie się zaś budowa dodatkowych ...          16000   \n",
       "\n",
       "                                        audiopath_local  \\\n",
       "0     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "1     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "2     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "3     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4     C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "...                                                 ...   \n",
       "4995  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4996  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4997  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4998  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "4999  C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...   \n",
       "\n",
       "                                      audiopath_project  \\\n",
       "0     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "1     ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "2     ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "3     ./data/testing_batch/clear/pwr-maleset-unk-tra...   \n",
       "4     ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "...                                                 ...   \n",
       "4995  ./data/testing_batch/clear/mailabs-corpus_libr...   \n",
       "4996  ./data/testing_batch/clear/pjatk-clarin_studio...   \n",
       "4997  ./data/testing_batch/clear/mozilla-common_voic...   \n",
       "4998  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "4999  ./data/testing_batch/clear/pjatk-clarin_mobile...   \n",
       "\n",
       "                                             noise_path         noise_class  \n",
       "0      .\\data\\UrbanSound8K\\audio\\fold2\\156893-7-9-0.wav          jackhammer  \n",
       "1       .\\data\\UrbanSound8K\\audio\\fold1\\40722-8-0-4.wav               siren  \n",
       "2      .\\data\\UrbanSound8K\\audio\\fold8\\125678-7-0-4.wav          jackhammer  \n",
       "3     .\\data\\UrbanSound8K\\audio\\fold9\\105029-7-2-16.wav          jackhammer  \n",
       "4     .\\data\\UrbanSound8K\\audio\\fold10\\99192-4-0-54.wav            drilling  \n",
       "...                                                 ...                 ...  \n",
       "4995                .\\data\\VISC Dataset SON\\7 (249).wav  crossover_interior  \n",
       "4996                .\\data\\VISC Dataset SON\\2 (172).wav    minibus_interior  \n",
       "4997                .\\data\\VISC Dataset SON\\5 (164).wav       jeep_interior  \n",
       "4998                .\\data\\VISC Dataset SON\\6 (638).wav      truck_interior  \n",
       "4999                .\\data\\VISC Dataset SON\\8 (302).wav  other_car_interior  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dataframe['sentence'] = full_df['ref_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\configuration_utils.py:365: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at alexcleu/wav2vec2-large-xlsr-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m resampler \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(\u001b[38;5;241m48_000\u001b[39m, \u001b[38;5;241m16_000\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m snr_dataframe \u001b[38;5;241m=\u001b[39m snr_dataframe\u001b[38;5;241m.\u001b[39mmap(speech_file_to_array_fn)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(batch):\n\u001b[0;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m processor(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_SNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10455\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[1;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[0;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m  10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m> 10455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(infer)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10360\u001b[0m )\n\u001b[1;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\frame.py:10453\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m> 10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mspeech_file_to_array_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_file_to_array_fn\u001b[39m(batch):\n\u001b[1;32m----> 6\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(chars_to_ignore_regex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      8\u001b[0m     speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_SNR_100\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m resampler(speech_array)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "  \n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"SNR_100\"])\n",
    "  \n",
    "    batch[\"speech_SNR_100\"] = resampler(speech_array).squeeze().numpy()\n",
    "  \n",
    "    return batch\n",
    "\n",
    "wer = load_metric(\"wer\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"alexcleu/wav2vec2-large-xlsr-polish\")\n",
    "model.to(\"cuda\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\;\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\“]'\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\n",
    "snr_dataframe = snr_dataframe.map(speech_file_to_array_fn)\n",
    "\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech_SNR_100\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "    \n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Assuming snr_dataframe is a DataFrame with columns like \"sentence\" and \"SNR_100\"\n",
    "result = snr_dataframe.map(evaluate, batched=True, batch_size=8)\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model jonatasgrosman/wav2vec2-large-xlsr-53-polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid file: 0    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n1    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n2    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n3    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n4    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\nName: audiopath_local, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n\u001b[0;32m     15\u001b[0m df_test_wav \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 16\u001b[0m df_test_wav \u001b[38;5;241m=\u001b[39m speech_file_to_array_fn(df_whisper[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(df_test_wav[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m'\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m, in \u001b[0;36mspeech_file_to_array_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_file_to_array_fn\u001b[39m(batch):\n\u001b[1;32m---> 10\u001b[0m     speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudiopath_local\u001b[39m\u001b[38;5;124m\"\u001b[39m], sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m)\n\u001b[0;32m     11\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m speech_array\n\u001b[0;32m     12\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    211\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\soundfile.py:1212\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_virtual(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_virtual_io(file),\n\u001b[0;32m   1210\u001b[0m                                     mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, _ffi\u001b[38;5;241m.\u001b[39mNULL)\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid file: 0    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n1    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n2    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n3    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\n4    C:\\Users\\Eryk\\.cache\\huggingface\\datasets\\down...\nName: audiopath_local, dtype: object"
     ]
    }
   ],
   "source": [
    "\n",
    "LANG_ID = \"pl\"\n",
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-polish\"\n",
    "SAMPLES = 5\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"SNR100\"], sr=16_000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"ref_orig\"].upper()\n",
    "    return batch\n",
    "\n",
    "df_test_wav = pd.DataFrame()\n",
    "df_test_wav = speech_file_to_array_fn(df_whisper[0:5])\n",
    "inputs = processor(df_test_wav['speech'], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Reference:\", test_dataset[i][\"sentence\"])\n",
    "    print(\"Prediction:\", predicted_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
