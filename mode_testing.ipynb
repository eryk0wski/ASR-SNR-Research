{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataframe with recordings paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio = pd.read_parquet('./data/parquets/SNR_testing_dataset.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audioname', 'dataset', 'ref_orig', 'sampling_rate', 'audiopath_bigos', 'audiopath_local', 'noise_path', 'noise_class', 'normalised_audio_path', 'normalised_noise_path', 'audio_SNR_100_path', 'audio_SNR_50_path', 'audio_SNR_25_path', 'audio_SNR_10_path', 'audio_SNR_5_path', 'audio_SNR_0.1_path', 'audio_SNR_-1_path', 'audio_SNR_-3_path', 'audio_SNR_-10_path']\n"
     ]
    }
   ],
   "source": [
    "print(df_audio.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling model Whisper v3 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the CUDA device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "torch_dtype = torch.float32  # You can adjust the dtype if needed\n",
    "\n",
    "# Load model and move it to CUDA\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create the pipeline with CUDA support\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866ccf0483bd44168cfc504ae63e6808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da11e1460f5a46f3a0d4f582ea1326fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9f03c5da404ebc8672e5f35a406aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ef9670656a4da9b3c64bbba3f7d68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edf32bf6bc3449e96a2d404a0f76a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbf340bcf1242a4816dfef329abd2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bd9401095d4310bf16b55e3de6c339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65e084ef3594c56ac9ebcaf32666edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b3092cee404eecb53823544e93482f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eryk\\anaconda3\\envs\\Magisterka\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "#whisper_results = []\n",
    "#for i in range(len(df_whisper)):\n",
    "#    sample = df_whisper['audiopath_local'][i]\n",
    "#    result = pipe(sample)\n",
    "#    whisper_results.append(result['text'])\n",
    "\n",
    "#df_whisper['whisper_pred'] = whisper_results\n",
    "snr_list = ['audio_SNR_100_path', 'audio_SNR_50_path', 'audio_SNR_25_path', 'audio_SNR_10_path', 'audio_SNR_5_path', 'audio_SNR_0.1_path', 'audio_SNR_-1_path', 'audio_SNR_-3_path', 'audio_SNR_-10_path']\n",
    "for snr in snr_list:\n",
    "    audio_paths = df_audio[snr].to_list()\n",
    "    results = []\n",
    "    for i in trange(len(audio_paths)):\n",
    "        sample = audio_paths[i]\n",
    "        result = pipe(sample, generate_kwargs={\"language\": \"polish\"})\n",
    "        results.append(result['text'])\n",
    "    col_name = f\"WER_{snr}\"\n",
    "    df_audio[col_name] = results \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_audio.to_parquet('./data/parquets/Whisper_SNR_WER.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model jonatasgrosman/wav2vec2-large-xlsr-53-polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio = pd.read_parquet('./data/parquets/SNR_testing_dataset.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audioname',\n",
       " 'dataset',\n",
       " 'ref_orig',\n",
       " 'sampling_rate',\n",
       " 'audiopath_bigos',\n",
       " 'audiopath_local',\n",
       " 'noise_path',\n",
       " 'noise_class',\n",
       " 'normalised_audio_path',\n",
       " 'normalised_noise_path',\n",
       " 'audio_SNR_100_path',\n",
       " 'audio_SNR_50_path',\n",
       " 'audio_SNR_25_path',\n",
       " 'audio_SNR_10_path',\n",
       " 'audio_SNR_5_path',\n",
       " 'audio_SNR_0.1_path',\n",
       " 'audio_SNR_-1_path',\n",
       " 'audio_SNR_-3_path',\n",
       " 'audio_SNR_-10_path']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-polish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-polish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audioname', 'dataset', 'ref_orig', 'sampling_rate', 'audiopath_bigos', 'audiopath_local', 'noise_path', 'noise_class', 'normalised_audio_path', 'normalised_noise_path', 'audio_SNR_100_path', 'audio_SNR_50_path', 'audio_SNR_25_path', 'audio_SNR_10_path', 'audio_SNR_5_path', 'audio_SNR_0.1_path', 'audio_SNR_-1_path', 'audio_SNR_-3_path', 'audio_SNR_-10_path'],\n",
      "    num_rows: 2500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch,column_name):\n",
    "    speech_array, sampling_rate = librosa.load(batch[column_name], sr=16_000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wav2wec = pd.DataFrame()\n",
    "#df_wav2wec[['audio_name','sentences']] = df_audio[['audiopath_bigos','ref_orig']]\n",
    "#df_wav2wec\n",
    "df_wav2wec = pd.read_parquet('./data/parquets/wav2wec_wer.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_name</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Wav2wec_SNR_100</th>\n",
       "      <th>Wav2wec_SNR_50</th>\n",
       "      <th>Wav2wec_SNR_25</th>\n",
       "      <th>Wav2wec_SNR_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair-mls-20-train-0009-04739.wav</td>\n",
       "      <td>tam nocne włóczęgi wołano z dachów jeżeli nie ...</td>\n",
       "      <td>hej wytam nocne marki - wołano z dachów - jeże...</td>\n",
       "      <td>hej wytam nocne marki - wołano z dachów - jeże...</td>\n",
       "      <td>hej wytam nocne marki  wołano d dachów - jeżel...</td>\n",
       "      <td>hej wytam nocne marki  wołano z dachób  jeżeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0488-00003.wav</td>\n",
       "      <td>w  pracy  studenci  chcieliby  przede  wszystk...</td>\n",
       "      <td>w pracy studenci chcieliby przede wszystkim od...</td>\n",
       "      <td>w pracy studenci chcieliby przede wszystkim od...</td>\n",
       "      <td>pracy studenci chcieliby przede wszystkim odcz...</td>\n",
       "      <td>traty studenci ścielidy przede wszystkim odczu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair-mls-20-train-0009-05501.wav</td>\n",
       "      <td>co to znaczy sam siebie zapytywał faraon czy g...</td>\n",
       "      <td>co to znaczy  sam siebie zapytywał faraon  czy...</td>\n",
       "      <td>co to znaczy  sam siebie zapytywał faraon  czy...</td>\n",
       "      <td>co to znaczy sam siebie zapytywał faraon  czy ...</td>\n",
       "      <td>co co znaczy sam siebie zapytywał taraon czy g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fair-mls-20-train-0021-01519.wav</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0335-00001.wav</td>\n",
       "      <td>zaokrągla  uziemienie  księdzu  liźnięcie  rol...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>za okrągle uziemienie księdzu liźnięcie role l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>fair-mls-20-train-0009-06517.wav</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyzn w państw...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić pis wszystkich mężczyznów z państ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-00218.wav</td>\n",
       "      <td>W odniesieniu do Lizbony, uczyniliśmy także po...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>podniesieniu do lizbony uczyniliśmy także post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01361.wav</td>\n",
       "      <td>Jej budżet to budżet, który wspiera inwestycje</td>\n",
       "      <td>jej pudszed to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej pudszet to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej budrzed to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej budrzet to budrzet który wzpiera inbescycję</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>fair-mls-20-train-0009-03165.wav</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2850-00179.wav</td>\n",
       "      <td>Prywatyzacja usług publicznych i społecznych r...</td>\n",
       "      <td>watyzacja usłub publicznych społecznych równie...</td>\n",
       "      <td>ratyzacja usłub publicznych społecznych równie...</td>\n",
       "      <td>ewatyzacja usług publicznych społecznych równi...</td>\n",
       "      <td>ewatysacja usług publicznych społecznych równi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           audio_name  \\\n",
       "0                    fair-mls-20-train-0009-04739.wav   \n",
       "1         pjatk-clarin_studio-15-train-0488-00003.wav   \n",
       "2                    fair-mls-20-train-0009-05501.wav   \n",
       "3                    fair-mls-20-train-0021-01519.wav   \n",
       "4         pjatk-clarin_studio-15-train-0335-00001.wav   \n",
       "...                                               ...   \n",
       "2495                 fair-mls-20-train-0009-06517.wav   \n",
       "2496  mozilla-common_voice_15-23-train-2851-00218.wav   \n",
       "2497  mozilla-common_voice_15-23-train-2856-01361.wav   \n",
       "2498                 fair-mls-20-train-0009-03165.wav   \n",
       "2499  mozilla-common_voice_15-23-train-2850-00179.wav   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     tam nocne włóczęgi wołano z dachów jeżeli nie ...   \n",
       "1     w  pracy  studenci  chcieliby  przede  wszystk...   \n",
       "2     co to znaczy sam siebie zapytywał faraon czy g...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągla  uziemienie  księdzu  liźnięcie  rol...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyzn w państw...   \n",
       "2496  W odniesieniu do Lizbony, uczyniliśmy także po...   \n",
       "2497     Jej budżet to budżet, który wspiera inwestycje   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  Prywatyzacja usług publicznych i społecznych r...   \n",
       "\n",
       "                                        Wav2wec_SNR_100  \\\n",
       "0     hej wytam nocne marki - wołano z dachów - jeże...   \n",
       "1     w pracy studenci chcieliby przede wszystkim od...   \n",
       "2     co to znaczy  sam siebie zapytywał faraon  czy...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej pudszed to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  watyzacja usłub publicznych społecznych równie...   \n",
       "\n",
       "                                         Wav2wec_SNR_50  \\\n",
       "0     hej wytam nocne marki - wołano z dachów - jeże...   \n",
       "1     w pracy studenci chcieliby przede wszystkim od...   \n",
       "2     co to znaczy  sam siebie zapytywał faraon  czy...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej pudszet to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  ratyzacja usłub publicznych społecznych równie...   \n",
       "\n",
       "                                         Wav2wec_SNR_25  \\\n",
       "0     hej wytam nocne marki  wołano d dachów - jeżel...   \n",
       "1     pracy studenci chcieliby przede wszystkim odcz...   \n",
       "2     co to znaczy sam siebie zapytywał faraon  czy ...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej budrzed to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  ewatyzacja usług publicznych społecznych równi...   \n",
       "\n",
       "                                         Wav2wec_SNR_10  \n",
       "0     hej wytam nocne marki  wołano z dachób  jeżeli...  \n",
       "1     traty studenci ścielidy przede wszystkim odczu...  \n",
       "2     co co znaczy sam siebie zapytywał taraon czy g...  \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...  \n",
       "4     za okrągle uziemienie księdzu liźnięcie role l...  \n",
       "...                                                 ...  \n",
       "2495  kazał zrobić pis wszystkich mężczyznów z państ...  \n",
       "2496  podniesieniu do lizbony uczyniliśmy także post...  \n",
       "2497    jej budrzet to budrzet który wzpiera inbescycję  \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...  \n",
       "2499  ewatysacja usług publicznych społecznych równi...  \n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wav2wec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc25e0d2764a7b8e3951892e043dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_25_path\n",
      "torch done for: audio_SNR_25_path\n",
      "predictions appended\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5d33e910334fb28872df167010894a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n",
      "inputs done for: audio_SNR_10_path\n",
      "torch done for: audio_SNR_10_path\n",
      "predictions appended\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae0bc36ffbc419796c57f6ed62ad82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import re\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decrease Batch Size\n",
    "batch_size = 25\n",
    "\n",
    "# Gradient Accumulation\n",
    "accumulate_gradients = True\n",
    "gradient_accumulation_steps = 4  # Accumulate gradients over 4 batches\n",
    "\n",
    "\n",
    "#snr_paths = ['audio_SNR_100_path', 'audio_SNR_50_path', 'audio_SNR_25_path', 'audio_SNR_10_path', 'audio_SNR_5_path', 'audio_SNR_0.1_path', 'audio_SNR_-1_path', 'audio_SNR_-3_path', 'audio_SNR_-10_path']\n",
    "\n",
    "#snr_paths = ['audio_SNR_100_path','audio_SNR_50_path']\n",
    "\n",
    "snr_paths = ['audio_SNR_25_path', 'audio_SNR_10_path', 'audio_SNR_5_path']\n",
    "\n",
    "for snr in snr_paths:\n",
    "    test_dataset = ds.map(lambda batch: speech_file_to_array_fn(batch, snr))\n",
    "    predictions = []\n",
    "    num_batches = math.ceil(len(test_dataset) / batch_size)\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(test_dataset))\n",
    "        \n",
    "        inputs = processor(test_dataset[\"speech\"][batch_start:batch_end], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "        inputs = inputs.to(device)\n",
    "        print('inputs done for:', snr)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "        print('torch done for:', snr)\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "        predictions.extend(predicted_sentences)\n",
    "        print('predictions appended')\n",
    "\n",
    "        # Gradient Accumulation\n",
    "        if accumulate_gradients and (i + 1) % gradient_accumulation_steps == 0:\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    del inputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    prefix = re.search(r'SNR_\\d+', snr).group()\n",
    "    col_name = f\"Wav2wec_{prefix}\"\n",
    "    df_wav2wec[col_name] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_name</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Wav2wec_SNR_100</th>\n",
       "      <th>Wav2wec_SNR_50</th>\n",
       "      <th>Wav2wec_SNR_25</th>\n",
       "      <th>Wav2wec_SNR_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair-mls-20-train-0009-04739.wav</td>\n",
       "      <td>tam nocne włóczęgi wołano z dachów jeżeli nie ...</td>\n",
       "      <td>hej wytam nocne marki - wołano z dachów - jeże...</td>\n",
       "      <td>hej wytam nocne marki - wołano z dachów - jeże...</td>\n",
       "      <td>hej wytam nocne marki  wołano d dachów - jeżel...</td>\n",
       "      <td>hej wytam nocne marki  wołano z dachób  jeżeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0488-00003.wav</td>\n",
       "      <td>w  pracy  studenci  chcieliby  przede  wszystk...</td>\n",
       "      <td>w pracy studenci chcieliby przede wszystkim od...</td>\n",
       "      <td>w pracy studenci chcieliby przede wszystkim od...</td>\n",
       "      <td>pracy studenci chcieliby przede wszystkim odcz...</td>\n",
       "      <td>traty studenci ścielidy przede wszystkim odczu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair-mls-20-train-0009-05501.wav</td>\n",
       "      <td>co to znaczy sam siebie zapytywał faraon czy g...</td>\n",
       "      <td>co to znaczy  sam siebie zapytywał faraon  czy...</td>\n",
       "      <td>co to znaczy  sam siebie zapytywał faraon  czy...</td>\n",
       "      <td>co to znaczy sam siebie zapytywał faraon  czy ...</td>\n",
       "      <td>co co znaczy sam siebie zapytywał taraon czy g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fair-mls-20-train-0021-01519.wav</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "      <td>tylko na piaszczystem wybrzeżu lub na łąkach b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pjatk-clarin_studio-15-train-0335-00001.wav</td>\n",
       "      <td>zaokrągla  uziemienie  księdzu  liźnięcie  rol...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>zaokrągle uziemienie księdzu liźnięcie role lo...</td>\n",
       "      <td>za okrągle uziemienie księdzu liźnięcie role l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>fair-mls-20-train-0009-06517.wav</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyzn w państw...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić spis wszystkich mężczyznón z pańs...</td>\n",
       "      <td>kazał zrobić pis wszystkich mężczyznów z państ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2851-00218.wav</td>\n",
       "      <td>W odniesieniu do Lizbony, uczyniliśmy także po...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>po dniesieniu do lizbony uczyniliśmy także pos...</td>\n",
       "      <td>podniesieniu do lizbony uczyniliśmy także post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2856-01361.wav</td>\n",
       "      <td>Jej budżet to budżet, który wspiera inwestycje</td>\n",
       "      <td>jej pudszed to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej pudszet to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej budrzed to budrzet który wspiera inwestycję</td>\n",
       "      <td>jej budrzet to budrzet który wzpiera inbescycję</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>fair-mls-20-train-0009-03165.wav</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "      <td>upłynęło już kilka godzin po zachodzie słońca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>mozilla-common_voice_15-23-train-2850-00179.wav</td>\n",
       "      <td>Prywatyzacja usług publicznych i społecznych r...</td>\n",
       "      <td>watyzacja usłub publicznych społecznych równie...</td>\n",
       "      <td>ratyzacja usłub publicznych społecznych równie...</td>\n",
       "      <td>ewatyzacja usług publicznych społecznych równi...</td>\n",
       "      <td>ewatysacja usług publicznych społecznych równi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           audio_name  \\\n",
       "0                    fair-mls-20-train-0009-04739.wav   \n",
       "1         pjatk-clarin_studio-15-train-0488-00003.wav   \n",
       "2                    fair-mls-20-train-0009-05501.wav   \n",
       "3                    fair-mls-20-train-0021-01519.wav   \n",
       "4         pjatk-clarin_studio-15-train-0335-00001.wav   \n",
       "...                                               ...   \n",
       "2495                 fair-mls-20-train-0009-06517.wav   \n",
       "2496  mozilla-common_voice_15-23-train-2851-00218.wav   \n",
       "2497  mozilla-common_voice_15-23-train-2856-01361.wav   \n",
       "2498                 fair-mls-20-train-0009-03165.wav   \n",
       "2499  mozilla-common_voice_15-23-train-2850-00179.wav   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     tam nocne włóczęgi wołano z dachów jeżeli nie ...   \n",
       "1     w  pracy  studenci  chcieliby  przede  wszystk...   \n",
       "2     co to znaczy sam siebie zapytywał faraon czy g...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągla  uziemienie  księdzu  liźnięcie  rol...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyzn w państw...   \n",
       "2496  W odniesieniu do Lizbony, uczyniliśmy także po...   \n",
       "2497     Jej budżet to budżet, który wspiera inwestycje   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  Prywatyzacja usług publicznych i społecznych r...   \n",
       "\n",
       "                                        Wav2wec_SNR_100  \\\n",
       "0     hej wytam nocne marki - wołano z dachów - jeże...   \n",
       "1     w pracy studenci chcieliby przede wszystkim od...   \n",
       "2     co to znaczy  sam siebie zapytywał faraon  czy...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej pudszed to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  watyzacja usłub publicznych społecznych równie...   \n",
       "\n",
       "                                         Wav2wec_SNR_50  \\\n",
       "0     hej wytam nocne marki - wołano z dachów - jeże...   \n",
       "1     w pracy studenci chcieliby przede wszystkim od...   \n",
       "2     co to znaczy  sam siebie zapytywał faraon  czy...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej pudszet to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  ratyzacja usłub publicznych społecznych równie...   \n",
       "\n",
       "                                         Wav2wec_SNR_25  \\\n",
       "0     hej wytam nocne marki  wołano d dachów - jeżel...   \n",
       "1     pracy studenci chcieliby przede wszystkim odcz...   \n",
       "2     co to znaczy sam siebie zapytywał faraon  czy ...   \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...   \n",
       "4     zaokrągle uziemienie księdzu liźnięcie role lo...   \n",
       "...                                                 ...   \n",
       "2495  kazał zrobić spis wszystkich mężczyznón z pańs...   \n",
       "2496  po dniesieniu do lizbony uczyniliśmy także pos...   \n",
       "2497    jej budrzed to budrzet który wspiera inwestycję   \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...   \n",
       "2499  ewatyzacja usług publicznych społecznych równi...   \n",
       "\n",
       "                                         Wav2wec_SNR_10  \n",
       "0     hej wytam nocne marki  wołano z dachób  jeżeli...  \n",
       "1     traty studenci ścielidy przede wszystkim odczu...  \n",
       "2     co co znaczy sam siebie zapytywał taraon czy g...  \n",
       "3     tylko na piaszczystem wybrzeżu lub na łąkach b...  \n",
       "4     za okrągle uziemienie księdzu liźnięcie role l...  \n",
       "...                                                 ...  \n",
       "2495  kazał zrobić pis wszystkich mężczyznów z państ...  \n",
       "2496  podniesieniu do lizbony uczyniliśmy także post...  \n",
       "2497    jej budrzet to budrzet który wzpiera inbescycję  \n",
       "2498  upłynęło już kilka godzin po zachodzie słońca ...  \n",
       "2499  ewatysacja usług publicznych społecznych równi...  \n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wav2wec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wav2wec.to_parquet('./data/parquets/wav2wec_wer.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ds.map(speech_file_to_array_fn)\n",
    "inputs = processor(test_dataset[\"speech\"][0:30], sampling_rate=16_000, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
